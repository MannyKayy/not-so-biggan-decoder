{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a folder called celeba in home dir where reconstructed images will be stored\n",
    "#Considered only 100000 images for training\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as utils\n",
    "import gc\n",
    "import pywt\n",
    "import IPython\n",
    "import random\n",
    "from random import sample\n",
    "with __import__('importnb').Notebook():\n",
    "        from PyTorch_notsobiggan_test64 import CelebaDataset, VAE, Flatten\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "CUDA = True\n",
    "BATCH_SIZE = 32\n",
    "LOG_INTERVAL = 5\n",
    "h_img = 64\n",
    "w_img = 64\n",
    "flat = h_img*w_img*3\n",
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=pywt.Wavelet('bior2.2')\n",
    "\n",
    "\n",
    "dec_hi = torch.Tensor(w.dec_hi[::-1]).cuda() \n",
    "dec_lo = torch.Tensor(w.dec_lo[::-1]).cuda()\n",
    "rec_hi = torch.Tensor(w.rec_hi).cuda()\n",
    "rec_lo = torch.Tensor(w.rec_lo).cuda()\n",
    "\n",
    "inv_filters = torch.stack([rec_lo.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                           rec_lo.unsqueeze(0)*rec_hi.unsqueeze(1),\n",
    "                           rec_hi.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                           rec_hi.unsqueeze(0)*rec_hi.unsqueeze(1)], dim=0)\n",
    "\n",
    "def iwt(vres, levels=1):\n",
    "    h = vres.size(2)\n",
    "    w = vres.size(3)\n",
    "    res = vres.contiguous().view(-1,h//2,2,w//2).transpose(1,2).contiguous().view(-1,4,h//2,w//2).clone()\n",
    "    print(res.shape)\n",
    "    if levels>1:\n",
    "        res[:,:1] = iwt(res[:,:1], levels=levels-1)\n",
    "    res = torch.nn.functional.conv_transpose2d(res, Variable(inv_filters[:,None]),stride=2)\n",
    "    res = res[:,:,2:-2,2:-2] #removing padding\n",
    "#     print(res.shape)\n",
    "    return res\n",
    "\n",
    "def truncated_normal_(tensor, mean=0, std=0.02):\n",
    "    size = tensor.shape\n",
    "    tmp = tensor.new_empty(size + (4,)).normal_()\n",
    "    valid = (tmp < 2) & (tmp > -2)\n",
    "    ind = valid.max(-1, keepdim=True)[1]\n",
    "    tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n",
    "    tensor.data.mul_(std).add_(mean)\n",
    "    \n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        with torch.no_grad():\n",
    "            truncated_normal_(m.weight.data, mean=0, std=0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight.data, mean=0, std=0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnIWT(nn.Module):\n",
    "    def __init__(self, image_channels=3, z_dim=100, device=None):\n",
    "        super(LearnIWT, self).__init__()\n",
    "        \n",
    "        if device is None:\n",
    "            self.cuda = False\n",
    "            self.device = None\n",
    "        else:\n",
    "            self.device = device\n",
    "            self.cuda = True\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # X - Y Residual Encoder\n",
    "        self.e1 = nn.Conv2d(3, 64, 4, stride=2, padding=1, bias=True, padding_mode='zeros') #[b, 64, 32, 32]\n",
    "        weights_init(self.e1)\n",
    "        self.instance_norm_e1 = nn.InstanceNorm2d(num_features=64, affine=False)\n",
    "\n",
    "        self.e2 = nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=True, padding_mode='zeros') #[b, 128, 16, 16]\n",
    "        weights_init(self.e2)\n",
    "        self.instance_norm_e2 = nn.InstanceNorm2d(num_features=128, affine=False)\n",
    "\n",
    "        self.e3 = nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=True, padding_mode='zeros') #[b, 256, 8, 8]\n",
    "        weights_init(self.e3)\n",
    "        self.instance_norm_e3 = nn.InstanceNorm2d(num_features=256, affine=False)\n",
    "\n",
    "        self.e4 = nn.Conv2d(256, 512, 4, stride=2, padding=1, bias=True, padding_mode='zeros') #[b, 512, 4, 4]\n",
    "        weights_init(self.e4)\n",
    "        self.instance_norm_e4 = nn.InstanceNorm2d(num_features=512, affine=False)\n",
    "        \n",
    "        self.fc_enc = nn.Linear(512 * 4 * 4, 256)\n",
    "        weights_init(self.fc_enc)\n",
    "        \n",
    "        self.fc_mean = nn.Linear(256, z_dim)\n",
    "        weights_init(self.fc_mean)\n",
    "        \n",
    "        self.fc_var = nn.Linear(256, z_dim)\n",
    "        weights_init(self.fc_var)\n",
    "        \n",
    "        # IWT Decoder        \n",
    "        self.d1 = nn.Linear(3 * 64 * 64, 3 * 64 * 64)\n",
    "        weights_init(self.d1)\n",
    "        self.mu1 = nn.Linear(z_dim, 3 * 64 * 64)\n",
    "        self.var1 = nn.Linear(z_dim, 3 * 64 * 64)\n",
    "        self.instance_norm_d1 = nn.InstanceNorm2d(num_features=3, affine=False)\n",
    "        self.iwt1 = nn.ConvTranspose2d(image_channels, image_channels, kernel_size=5, stride=1, padding=2)\n",
    "        \n",
    "        self.d2 = nn.Linear(3 * 64 * 64, 3 * 64 * 64)\n",
    "        weights_init(self.d2)\n",
    "        self.mu2 = nn.Linear(z_dim, 3 * 64 * 64)\n",
    "        self.var2 = nn.Linear(z_dim, 3 * 64 * 64)\n",
    "        self.instance_norm_d2 = nn.InstanceNorm2d(num_features=3, affine=False)\n",
    "        self.iwt2 = nn.ConvTranspose2d(image_channels, image_channels, kernel_size=5, stride=1, padding=2)\n",
    "        \n",
    "    \n",
    "    def encode(self, x, y):\n",
    "        h = self.leakyrelu(self.instance_norm_e1(self.e1(x-y)))   #[b, 64, 32, 32]\n",
    "        h = self.leakyrelu(self.instance_norm_e2(self.e2(h)))     #[b, 128, 16, 16]\n",
    "        h = self.leakyrelu(self.instance_norm_e3(self.e3(h)))     #[b, 256, 8, 8]\n",
    "        h = self.leakyrelu(self.instance_norm_e4(self.e4(h)))     #[b, 512, 4, 4]\n",
    "        h = self.leakyrelu(self.fc_enc(h.view(-1,512*4*4)))       #[b, 512 * 4 * 4]\n",
    "        \n",
    "        return self.fc_mean(h), F.softplus(self.fc_var(h))        #[b, z_dim]\n",
    "\n",
    "    def reparameterize(self, mu, var):\n",
    "        std = torch.sqrt(var)\n",
    "        if self.cuda:\n",
    "            eps = torch.FloatTensor(std.size()).normal_().to(self.device)\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu) \n",
    "    \n",
    "    def decode(self, y, z):\n",
    "        mu = self.mu1(z).reshape(-1, 3, 64, 64)\n",
    "        var = self.var1(z).reshape(-1, 3, 64, 64)\n",
    "        h = self.leakyrelu(var*self.instance_norm_d1(self.d1(y.view(y.shape[0], -1)).reshape(-1, 3, 64, 64)) + mu) #[b, 3, 64, 64]\n",
    "        h = self.leakyrelu(self.iwt1(h))                               #[b, 3, 64, 64]\n",
    "        \n",
    "        mu = self.mu2(z).reshape(-1, 3, 64, 64)\n",
    "        var = self.var2(z).reshape(-1, 3, 64, 64)\n",
    "        h = self.leakyrelu(var*self.instance_norm_d2(self.d1(h.view(h.shape[0], -1)).reshape(-1, 3, 64, 64)) + mu) #[b, 3, 64, 64]\n",
    "        h = self.leakyrelu(self.iwt2(h))                               #[b, 3, 64, 64]\n",
    "        \n",
    "        return self.sigmoid(h)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        mu, var = self.encode(x, y)\n",
    "        if self.training:\n",
    "            z = self.reparameterize(mu, var)\n",
    "        else:\n",
    "            z = mu\n",
    "        x_hat = self.decode(y, z)\n",
    "        \n",
    "        return x_hat, mu, var\n",
    "        \n",
    "        \n",
    "    def loss_function(self, x, x_hat, mu, var) -> Variable:\n",
    "        \n",
    "        # Loss btw reconstructed img and original img\n",
    "        BCE = F.mse_loss(x_hat.view(-1), x.view(-1))\n",
    "        \n",
    "        logvar = torch.log(var)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) * 0.01\n",
    "\n",
    "        return BCE + KLD\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = torch.zeros((32,3,32,32))\n",
    "# test1 = test.contiguous().view(-1,32//2,2,32//2).transpose(1,2).contiguous().view(-1,4,32//2,32//2).clone()\n",
    "# print(test1.shape)\n",
    "# #torch.nn.functional.conv_transpose2d(test1.cuda(), Variable(inv_filters[:,None]),stride=2)\n",
    "# t = nn.ConvTranspose2d(3, 3, kernel_size=6, stride=2)\n",
    "# t1 = Variable(inv_filters[:,None])\n",
    "# print(t1.shape)\n",
    "# print(t.weight.shape)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     t.weight = torch.nn.Parameter(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create celeba dataset\n",
    "root_dir = \"celeba64/\"\n",
    "image_files = os.listdir(root_dir)\n",
    "train_dataset = CelebaDataset('celeba64/', image_files, WT=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=10, shuffle=True)\n",
    "sample_dataset = Subset(train_dataset, sample(range(len(train_dataset)), 8))\n",
    "sample_loader = DataLoader(sample_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeroing out all other patches than the first for WT image: 4D: B * C * H * W\n",
    "def zero_patches(img):\n",
    "    zeros = torch.zeros((img.shape[0], img.shape[1], img.shape[2], img.shape[3]))\n",
    "    zeros[:,:,:16,:16] = img[:,:,:16,:16]\n",
    "    \n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, train_loader):\n",
    "    # toggle model to train mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        if CUDA:\n",
    "            data0 = data.to('cuda:0')\n",
    "            data1 = data.clone().to('cuda:1')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get Y\n",
    "        Y = wt_model(data1)[0]\n",
    "        # Zeroing out all other patches\n",
    "        Y = zero_patches(Y)\n",
    "        x_hat, mu, var = iwt_model(data0, Y.to('cuda:0'))\n",
    "        # Fix loss function\n",
    "        loss = iwt_model.loss_function(x_hat, data0, mu, var)\n",
    "        loss.backward()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        train_loss += loss\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data),\n",
    "                                                                           len(train_loader.dataset),\n",
    "                                                                           100. * batch_idx / len(train_loader),\n",
    "                                                                           loss / len(data)))\n",
    "            \n",
    "            n = min(data.size(0), 8)  \n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 0.085773\n",
      "Train Epoch: 1 [160/10000 (2%)]\tLoss: 0.025499\n",
      "Train Epoch: 1 [320/10000 (3%)]\tLoss: 0.009889\n",
      "Train Epoch: 1 [480/10000 (5%)]\tLoss: 0.006671\n",
      "Train Epoch: 1 [640/10000 (6%)]\tLoss: 0.004920\n",
      "Train Epoch: 1 [800/10000 (8%)]\tLoss: 0.003916\n",
      "Train Epoch: 1 [960/10000 (10%)]\tLoss: 0.003503\n",
      "Train Epoch: 1 [1120/10000 (11%)]\tLoss: 0.003079\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 0.002802\n",
      "Train Epoch: 1 [1440/10000 (14%)]\tLoss: 0.002888\n",
      "Train Epoch: 1 [1600/10000 (16%)]\tLoss: 0.002787\n",
      "Train Epoch: 1 [1760/10000 (18%)]\tLoss: 0.002635\n",
      "Train Epoch: 1 [1920/10000 (19%)]\tLoss: 0.002524\n",
      "Train Epoch: 1 [2080/10000 (21%)]\tLoss: 0.002692\n",
      "Train Epoch: 1 [2240/10000 (22%)]\tLoss: 0.002817\n",
      "Train Epoch: 1 [2400/10000 (24%)]\tLoss: 0.002504\n",
      "Train Epoch: 1 [2560/10000 (26%)]\tLoss: 0.002422\n",
      "Train Epoch: 1 [2720/10000 (27%)]\tLoss: 0.002507\n",
      "Train Epoch: 1 [2880/10000 (29%)]\tLoss: 0.002432\n",
      "Train Epoch: 1 [3040/10000 (30%)]\tLoss: 0.002254\n",
      "Train Epoch: 1 [3200/10000 (32%)]\tLoss: 0.002266\n",
      "Train Epoch: 1 [3360/10000 (34%)]\tLoss: 0.002218\n",
      "Train Epoch: 1 [3520/10000 (35%)]\tLoss: 0.002362\n",
      "Train Epoch: 1 [3680/10000 (37%)]\tLoss: 0.002267\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 0.002099\n",
      "Train Epoch: 1 [4000/10000 (40%)]\tLoss: 0.002232\n",
      "Train Epoch: 1 [4160/10000 (42%)]\tLoss: 0.002278\n",
      "Train Epoch: 1 [4320/10000 (43%)]\tLoss: 0.002160\n",
      "Train Epoch: 1 [4480/10000 (45%)]\tLoss: 0.002013\n",
      "Train Epoch: 1 [4640/10000 (46%)]\tLoss: 0.001791\n",
      "Train Epoch: 1 [4800/10000 (48%)]\tLoss: 0.001939\n",
      "Train Epoch: 1 [4960/10000 (50%)]\tLoss: 0.002076\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 0.001926\n",
      "Train Epoch: 1 [5280/10000 (53%)]\tLoss: 0.001808\n",
      "Train Epoch: 1 [5440/10000 (54%)]\tLoss: 0.001970\n",
      "Train Epoch: 1 [5600/10000 (56%)]\tLoss: 0.001743\n",
      "Train Epoch: 1 [5760/10000 (58%)]\tLoss: 0.002047\n",
      "Train Epoch: 1 [5920/10000 (59%)]\tLoss: 0.001968\n",
      "Train Epoch: 1 [6080/10000 (61%)]\tLoss: 0.001816\n",
      "Train Epoch: 1 [6240/10000 (62%)]\tLoss: 0.001697\n",
      "Train Epoch: 1 [6400/10000 (64%)]\tLoss: 0.001847\n",
      "Train Epoch: 1 [6560/10000 (65%)]\tLoss: 0.001741\n",
      "Train Epoch: 1 [6720/10000 (67%)]\tLoss: 0.001682\n",
      "Train Epoch: 1 [6880/10000 (69%)]\tLoss: 0.001793\n",
      "Train Epoch: 1 [7040/10000 (70%)]\tLoss: 0.001825\n",
      "Train Epoch: 1 [7200/10000 (72%)]\tLoss: 0.001688\n",
      "Train Epoch: 1 [7360/10000 (73%)]\tLoss: 0.001669\n",
      "Train Epoch: 1 [7520/10000 (75%)]\tLoss: 0.001768\n",
      "Train Epoch: 1 [7680/10000 (77%)]\tLoss: 0.001692\n",
      "Train Epoch: 1 [7840/10000 (78%)]\tLoss: 0.001647\n",
      "Train Epoch: 1 [8000/10000 (80%)]\tLoss: 0.001823\n",
      "Train Epoch: 1 [8160/10000 (81%)]\tLoss: 0.001623\n",
      "Train Epoch: 1 [8320/10000 (83%)]\tLoss: 0.001754\n",
      "Train Epoch: 1 [8480/10000 (85%)]\tLoss: 0.001739\n",
      "Train Epoch: 1 [8640/10000 (86%)]\tLoss: 0.001786\n",
      "Train Epoch: 1 [8800/10000 (88%)]\tLoss: 0.001640\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 0.001624\n",
      "Train Epoch: 1 [9120/10000 (91%)]\tLoss: 0.001486\n",
      "Train Epoch: 1 [9280/10000 (93%)]\tLoss: 0.001723\n",
      "Train Epoch: 1 [9440/10000 (94%)]\tLoss: 0.001694\n",
      "Train Epoch: 1 [9600/10000 (96%)]\tLoss: 0.001568\n",
      "Train Epoch: 1 [9760/10000 (97%)]\tLoss: 0.001449\n",
      "Train Epoch: 1 [9920/10000 (99%)]\tLoss: 0.001399\n",
      "====> Epoch: 1 Average loss: 0.0042\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 0.001482\n",
      "Train Epoch: 2 [160/10000 (2%)]\tLoss: 0.001616\n",
      "Train Epoch: 2 [320/10000 (3%)]\tLoss: 0.001651\n",
      "Train Epoch: 2 [480/10000 (5%)]\tLoss: 0.001524\n",
      "Train Epoch: 2 [640/10000 (6%)]\tLoss: 0.001626\n",
      "Train Epoch: 2 [800/10000 (8%)]\tLoss: 0.001498\n",
      "Train Epoch: 2 [960/10000 (10%)]\tLoss: 0.001537\n",
      "Train Epoch: 2 [1120/10000 (11%)]\tLoss: 0.001469\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 0.001651\n",
      "Train Epoch: 2 [1440/10000 (14%)]\tLoss: 0.001438\n",
      "Train Epoch: 2 [1600/10000 (16%)]\tLoss: 0.001609\n",
      "Train Epoch: 2 [1760/10000 (18%)]\tLoss: 0.001418\n",
      "Train Epoch: 2 [1920/10000 (19%)]\tLoss: 0.001354\n",
      "Train Epoch: 2 [2080/10000 (21%)]\tLoss: 0.001565\n",
      "Train Epoch: 2 [2240/10000 (22%)]\tLoss: 0.001529\n",
      "Train Epoch: 2 [2400/10000 (24%)]\tLoss: 0.001371\n",
      "Train Epoch: 2 [2560/10000 (26%)]\tLoss: 0.001399\n",
      "Train Epoch: 2 [2720/10000 (27%)]\tLoss: 0.001290\n",
      "Train Epoch: 2 [2880/10000 (29%)]\tLoss: 0.001469\n",
      "Train Epoch: 2 [3040/10000 (30%)]\tLoss: 0.001411\n",
      "Train Epoch: 2 [3200/10000 (32%)]\tLoss: 0.001610\n",
      "Train Epoch: 2 [3360/10000 (34%)]\tLoss: 0.001358\n",
      "Train Epoch: 2 [3520/10000 (35%)]\tLoss: 0.001446\n",
      "Train Epoch: 2 [3680/10000 (37%)]\tLoss: 0.001431\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 0.001448\n",
      "Train Epoch: 2 [4000/10000 (40%)]\tLoss: 0.001380\n",
      "Train Epoch: 2 [4160/10000 (42%)]\tLoss: 0.001517\n",
      "Train Epoch: 2 [4320/10000 (43%)]\tLoss: 0.001612\n",
      "Train Epoch: 2 [4480/10000 (45%)]\tLoss: 0.001512\n",
      "Train Epoch: 2 [4640/10000 (46%)]\tLoss: 0.001414\n",
      "Train Epoch: 2 [4800/10000 (48%)]\tLoss: 0.001378\n",
      "Train Epoch: 2 [4960/10000 (50%)]\tLoss: 0.001443\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 0.001664\n",
      "Train Epoch: 2 [5280/10000 (53%)]\tLoss: 0.001438\n",
      "Train Epoch: 2 [5440/10000 (54%)]\tLoss: 0.001354\n",
      "Train Epoch: 2 [5600/10000 (56%)]\tLoss: 0.001395\n",
      "Train Epoch: 2 [5760/10000 (58%)]\tLoss: 0.001431\n",
      "Train Epoch: 2 [5920/10000 (59%)]\tLoss: 0.001321\n",
      "Train Epoch: 2 [6080/10000 (61%)]\tLoss: 0.001358\n",
      "Train Epoch: 2 [6240/10000 (62%)]\tLoss: 0.001398\n",
      "Train Epoch: 2 [6400/10000 (64%)]\tLoss: 0.001353\n",
      "Train Epoch: 2 [6560/10000 (65%)]\tLoss: 0.001418\n",
      "Train Epoch: 2 [6720/10000 (67%)]\tLoss: 0.001353\n",
      "Train Epoch: 2 [6880/10000 (69%)]\tLoss: 0.001454\n",
      "Train Epoch: 2 [7040/10000 (70%)]\tLoss: 0.001467\n",
      "Train Epoch: 2 [7200/10000 (72%)]\tLoss: 0.001257\n",
      "Train Epoch: 2 [7360/10000 (73%)]\tLoss: 0.001346\n",
      "Train Epoch: 2 [7520/10000 (75%)]\tLoss: 0.001605\n",
      "Train Epoch: 2 [7680/10000 (77%)]\tLoss: 0.001495\n",
      "Train Epoch: 2 [7840/10000 (78%)]\tLoss: 0.001255\n",
      "Train Epoch: 2 [8000/10000 (80%)]\tLoss: 0.001408\n",
      "Train Epoch: 2 [8160/10000 (81%)]\tLoss: 0.001359\n",
      "Train Epoch: 2 [8320/10000 (83%)]\tLoss: 0.001247\n",
      "Train Epoch: 2 [8480/10000 (85%)]\tLoss: 0.001372\n",
      "Train Epoch: 2 [8640/10000 (86%)]\tLoss: 0.001515\n",
      "Train Epoch: 2 [8800/10000 (88%)]\tLoss: 0.001315\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 0.001214\n",
      "Train Epoch: 2 [9120/10000 (91%)]\tLoss: 0.001328\n",
      "Train Epoch: 2 [9280/10000 (93%)]\tLoss: 0.001276\n",
      "Train Epoch: 2 [9440/10000 (94%)]\tLoss: 0.001436\n",
      "Train Epoch: 2 [9600/10000 (96%)]\tLoss: 0.001318\n",
      "Train Epoch: 2 [9760/10000 (97%)]\tLoss: 0.001185\n",
      "Train Epoch: 2 [9920/10000 (99%)]\tLoss: 0.001179\n",
      "====> Epoch: 2 Average loss: 0.0014\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 0.001413\n",
      "Train Epoch: 3 [160/10000 (2%)]\tLoss: 0.001237\n",
      "Train Epoch: 3 [320/10000 (3%)]\tLoss: 0.001273\n",
      "Train Epoch: 3 [480/10000 (5%)]\tLoss: 0.001266\n",
      "Train Epoch: 3 [640/10000 (6%)]\tLoss: 0.001170\n",
      "Train Epoch: 3 [800/10000 (8%)]\tLoss: 0.001253\n",
      "Train Epoch: 3 [960/10000 (10%)]\tLoss: 0.001312\n",
      "Train Epoch: 3 [1120/10000 (11%)]\tLoss: 0.001132\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 0.001365\n",
      "Train Epoch: 3 [1440/10000 (14%)]\tLoss: 0.001098\n",
      "Train Epoch: 3 [1600/10000 (16%)]\tLoss: 0.001243\n",
      "Train Epoch: 3 [1760/10000 (18%)]\tLoss: 0.001181\n",
      "Train Epoch: 3 [1920/10000 (19%)]\tLoss: 0.001463\n",
      "Train Epoch: 3 [2080/10000 (21%)]\tLoss: 0.001307\n",
      "Train Epoch: 3 [2240/10000 (22%)]\tLoss: 0.001371\n",
      "Train Epoch: 3 [2400/10000 (24%)]\tLoss: 0.001317\n",
      "Train Epoch: 3 [2560/10000 (26%)]\tLoss: 0.001203\n",
      "Train Epoch: 3 [2720/10000 (27%)]\tLoss: 0.001295\n",
      "Train Epoch: 3 [2880/10000 (29%)]\tLoss: 0.001195\n",
      "Train Epoch: 3 [3040/10000 (30%)]\tLoss: 0.001340\n",
      "Train Epoch: 3 [3200/10000 (32%)]\tLoss: 0.001355\n",
      "Train Epoch: 3 [3360/10000 (34%)]\tLoss: 0.001158\n",
      "Train Epoch: 3 [3520/10000 (35%)]\tLoss: 0.001326\n",
      "Train Epoch: 3 [3680/10000 (37%)]\tLoss: 0.001309\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 0.001169\n",
      "Train Epoch: 3 [4000/10000 (40%)]\tLoss: 0.001384\n",
      "Train Epoch: 3 [4160/10000 (42%)]\tLoss: 0.001307\n",
      "Train Epoch: 3 [4320/10000 (43%)]\tLoss: 0.001229\n",
      "Train Epoch: 3 [4480/10000 (45%)]\tLoss: 0.001221\n",
      "Train Epoch: 3 [4640/10000 (46%)]\tLoss: 0.001129\n",
      "Train Epoch: 3 [4800/10000 (48%)]\tLoss: 0.001191\n",
      "Train Epoch: 3 [4960/10000 (50%)]\tLoss: 0.001191\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 0.001124\n",
      "Train Epoch: 3 [5280/10000 (53%)]\tLoss: 0.001103\n",
      "Train Epoch: 3 [5440/10000 (54%)]\tLoss: 0.001232\n",
      "Train Epoch: 3 [5600/10000 (56%)]\tLoss: 0.001272\n",
      "Train Epoch: 3 [5760/10000 (58%)]\tLoss: 0.001318\n",
      "Train Epoch: 3 [5920/10000 (59%)]\tLoss: 0.001090\n",
      "Train Epoch: 3 [6080/10000 (61%)]\tLoss: 0.001159\n",
      "Train Epoch: 3 [6240/10000 (62%)]\tLoss: 0.001179\n",
      "Train Epoch: 3 [6400/10000 (64%)]\tLoss: 0.001509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [6560/10000 (65%)]\tLoss: 0.001359\n",
      "Train Epoch: 3 [6720/10000 (67%)]\tLoss: 0.001275\n",
      "Train Epoch: 3 [6880/10000 (69%)]\tLoss: 0.001192\n",
      "Train Epoch: 3 [7040/10000 (70%)]\tLoss: 0.001250\n",
      "Train Epoch: 3 [7200/10000 (72%)]\tLoss: 0.001246\n",
      "Train Epoch: 3 [7360/10000 (73%)]\tLoss: 0.001235\n",
      "Train Epoch: 3 [7520/10000 (75%)]\tLoss: 0.001062\n",
      "Train Epoch: 3 [7680/10000 (77%)]\tLoss: 0.001226\n",
      "Train Epoch: 3 [7840/10000 (78%)]\tLoss: 0.001219\n",
      "Train Epoch: 3 [8000/10000 (80%)]\tLoss: 0.001228\n",
      "Train Epoch: 3 [8160/10000 (81%)]\tLoss: 0.001153\n",
      "Train Epoch: 3 [8320/10000 (83%)]\tLoss: 0.001174\n",
      "Train Epoch: 3 [8480/10000 (85%)]\tLoss: 0.001167\n",
      "Train Epoch: 3 [8640/10000 (86%)]\tLoss: 0.001180\n",
      "Train Epoch: 3 [8800/10000 (88%)]\tLoss: 0.001087\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 0.001304\n",
      "Train Epoch: 3 [9120/10000 (91%)]\tLoss: 0.001151\n",
      "Train Epoch: 3 [9280/10000 (93%)]\tLoss: 0.001159\n",
      "Train Epoch: 3 [9440/10000 (94%)]\tLoss: 0.001006\n",
      "Train Epoch: 3 [9600/10000 (96%)]\tLoss: 0.001174\n",
      "Train Epoch: 3 [9760/10000 (97%)]\tLoss: 0.001159\n",
      "Train Epoch: 3 [9920/10000 (99%)]\tLoss: 0.001207\n",
      "====> Epoch: 3 Average loss: 0.0012\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.001137\n",
      "Train Epoch: 4 [160/10000 (2%)]\tLoss: 0.001339\n",
      "Train Epoch: 4 [320/10000 (3%)]\tLoss: 0.001129\n",
      "Train Epoch: 4 [480/10000 (5%)]\tLoss: 0.001170\n",
      "Train Epoch: 4 [640/10000 (6%)]\tLoss: 0.001104\n",
      "Train Epoch: 4 [800/10000 (8%)]\tLoss: 0.001219\n",
      "Train Epoch: 4 [960/10000 (10%)]\tLoss: 0.001331\n",
      "Train Epoch: 4 [1120/10000 (11%)]\tLoss: 0.001132\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 0.001133\n",
      "Train Epoch: 4 [1440/10000 (14%)]\tLoss: 0.001118\n",
      "Train Epoch: 4 [1600/10000 (16%)]\tLoss: 0.001105\n",
      "Train Epoch: 4 [1760/10000 (18%)]\tLoss: 0.001143\n",
      "Train Epoch: 4 [1920/10000 (19%)]\tLoss: 0.001232\n",
      "Train Epoch: 4 [2080/10000 (21%)]\tLoss: 0.001116\n",
      "Train Epoch: 4 [2240/10000 (22%)]\tLoss: 0.001224\n",
      "Train Epoch: 4 [2400/10000 (24%)]\tLoss: 0.001181\n",
      "Train Epoch: 4 [2560/10000 (26%)]\tLoss: 0.001043\n",
      "Train Epoch: 4 [2720/10000 (27%)]\tLoss: 0.001230\n",
      "Train Epoch: 4 [2880/10000 (29%)]\tLoss: 0.001083\n",
      "Train Epoch: 4 [3040/10000 (30%)]\tLoss: 0.001116\n",
      "Train Epoch: 4 [3200/10000 (32%)]\tLoss: 0.001125\n",
      "Train Epoch: 4 [3360/10000 (34%)]\tLoss: 0.001073\n",
      "Train Epoch: 4 [3520/10000 (35%)]\tLoss: 0.001184\n",
      "Train Epoch: 4 [3680/10000 (37%)]\tLoss: 0.001003\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 0.001234\n",
      "Train Epoch: 4 [4000/10000 (40%)]\tLoss: 0.001161\n",
      "Train Epoch: 4 [4160/10000 (42%)]\tLoss: 0.001150\n",
      "Train Epoch: 4 [4320/10000 (43%)]\tLoss: 0.001092\n",
      "Train Epoch: 4 [4480/10000 (45%)]\tLoss: 0.001129\n",
      "Train Epoch: 4 [4640/10000 (46%)]\tLoss: 0.001155\n",
      "Train Epoch: 4 [4800/10000 (48%)]\tLoss: 0.001145\n",
      "Train Epoch: 4 [4960/10000 (50%)]\tLoss: 0.001205\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 0.001160\n",
      "Train Epoch: 4 [5280/10000 (53%)]\tLoss: 0.001225\n",
      "Train Epoch: 4 [5440/10000 (54%)]\tLoss: 0.001087\n",
      "Train Epoch: 4 [5600/10000 (56%)]\tLoss: 0.001038\n",
      "Train Epoch: 4 [5760/10000 (58%)]\tLoss: 0.001198\n",
      "Train Epoch: 4 [5920/10000 (59%)]\tLoss: 0.001103\n",
      "Train Epoch: 4 [6080/10000 (61%)]\tLoss: 0.001077\n",
      "Train Epoch: 4 [6240/10000 (62%)]\tLoss: 0.000985\n",
      "Train Epoch: 4 [6400/10000 (64%)]\tLoss: 0.001100\n",
      "Train Epoch: 4 [6560/10000 (65%)]\tLoss: 0.001163\n",
      "Train Epoch: 4 [6720/10000 (67%)]\tLoss: 0.001414\n",
      "Train Epoch: 4 [6880/10000 (69%)]\tLoss: 0.001134\n",
      "Train Epoch: 4 [7040/10000 (70%)]\tLoss: 0.001011\n",
      "Train Epoch: 4 [7200/10000 (72%)]\tLoss: 0.001025\n",
      "Train Epoch: 4 [7360/10000 (73%)]\tLoss: 0.001064\n",
      "Train Epoch: 4 [7520/10000 (75%)]\tLoss: 0.001051\n",
      "Train Epoch: 4 [7680/10000 (77%)]\tLoss: 0.001079\n",
      "Train Epoch: 4 [7840/10000 (78%)]\tLoss: 0.001215\n",
      "Train Epoch: 4 [8000/10000 (80%)]\tLoss: 0.000968\n",
      "Train Epoch: 4 [8160/10000 (81%)]\tLoss: 0.001141\n",
      "Train Epoch: 4 [8320/10000 (83%)]\tLoss: 0.001108\n",
      "Train Epoch: 4 [8480/10000 (85%)]\tLoss: 0.001080\n",
      "Train Epoch: 4 [8640/10000 (86%)]\tLoss: 0.001148\n",
      "Train Epoch: 4 [8800/10000 (88%)]\tLoss: 0.001133\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 0.001015\n",
      "Train Epoch: 4 [9120/10000 (91%)]\tLoss: 0.000977\n",
      "Train Epoch: 4 [9280/10000 (93%)]\tLoss: 0.001133\n",
      "Train Epoch: 4 [9440/10000 (94%)]\tLoss: 0.001139\n",
      "Train Epoch: 4 [9600/10000 (96%)]\tLoss: 0.001177\n",
      "Train Epoch: 4 [9760/10000 (97%)]\tLoss: 0.001068\n",
      "Train Epoch: 4 [9920/10000 (99%)]\tLoss: 0.001020\n",
      "====> Epoch: 4 Average loss: 0.0011\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 0.001080\n",
      "Train Epoch: 5 [160/10000 (2%)]\tLoss: 0.001626\n",
      "Train Epoch: 5 [320/10000 (3%)]\tLoss: 0.001111\n",
      "Train Epoch: 5 [480/10000 (5%)]\tLoss: 0.001158\n",
      "Train Epoch: 5 [640/10000 (6%)]\tLoss: 0.001113\n",
      "Train Epoch: 5 [800/10000 (8%)]\tLoss: 0.001081\n",
      "Train Epoch: 5 [960/10000 (10%)]\tLoss: 0.000984\n",
      "Train Epoch: 5 [1120/10000 (11%)]\tLoss: 0.001072\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 0.001128\n",
      "Train Epoch: 5 [1440/10000 (14%)]\tLoss: 0.001058\n",
      "Train Epoch: 5 [1600/10000 (16%)]\tLoss: 0.001015\n",
      "Train Epoch: 5 [1760/10000 (18%)]\tLoss: 0.001015\n",
      "Train Epoch: 5 [1920/10000 (19%)]\tLoss: 0.001092\n",
      "Train Epoch: 5 [2080/10000 (21%)]\tLoss: 0.001042\n",
      "Train Epoch: 5 [2240/10000 (22%)]\tLoss: 0.000948\n",
      "Train Epoch: 5 [2400/10000 (24%)]\tLoss: 0.001005\n",
      "Train Epoch: 5 [2560/10000 (26%)]\tLoss: 0.001016\n",
      "Train Epoch: 5 [2720/10000 (27%)]\tLoss: 0.001104\n",
      "Train Epoch: 5 [2880/10000 (29%)]\tLoss: 0.001039\n",
      "Train Epoch: 5 [3040/10000 (30%)]\tLoss: 0.001090\n",
      "Train Epoch: 5 [3200/10000 (32%)]\tLoss: 0.001030\n",
      "Train Epoch: 5 [3360/10000 (34%)]\tLoss: 0.001038\n",
      "Train Epoch: 5 [3520/10000 (35%)]\tLoss: 0.000954\n",
      "Train Epoch: 5 [3680/10000 (37%)]\tLoss: 0.001021\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 0.000965\n",
      "Train Epoch: 5 [4000/10000 (40%)]\tLoss: 0.001026\n",
      "Train Epoch: 5 [4160/10000 (42%)]\tLoss: 0.001020\n",
      "Train Epoch: 5 [4320/10000 (43%)]\tLoss: 0.001014\n",
      "Train Epoch: 5 [4480/10000 (45%)]\tLoss: 0.001016\n",
      "Train Epoch: 5 [4640/10000 (46%)]\tLoss: 0.001035\n",
      "Train Epoch: 5 [4800/10000 (48%)]\tLoss: 0.001069\n",
      "Train Epoch: 5 [4960/10000 (50%)]\tLoss: 0.001012\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 0.001031\n",
      "Train Epoch: 5 [5280/10000 (53%)]\tLoss: 0.001012\n",
      "Train Epoch: 5 [5440/10000 (54%)]\tLoss: 0.000965\n",
      "Train Epoch: 5 [5600/10000 (56%)]\tLoss: 0.000971\n",
      "Train Epoch: 5 [5760/10000 (58%)]\tLoss: 0.001034\n",
      "Train Epoch: 5 [5920/10000 (59%)]\tLoss: 0.000955\n",
      "Train Epoch: 5 [6080/10000 (61%)]\tLoss: 0.001024\n",
      "Train Epoch: 5 [6240/10000 (62%)]\tLoss: 0.001108\n",
      "Train Epoch: 5 [6400/10000 (64%)]\tLoss: 0.001053\n",
      "Train Epoch: 5 [6560/10000 (65%)]\tLoss: 0.001076\n",
      "Train Epoch: 5 [6720/10000 (67%)]\tLoss: 0.001127\n",
      "Train Epoch: 5 [6880/10000 (69%)]\tLoss: 0.001063\n",
      "Train Epoch: 5 [7040/10000 (70%)]\tLoss: 0.001124\n",
      "Train Epoch: 5 [7200/10000 (72%)]\tLoss: 0.001088\n",
      "Train Epoch: 5 [7360/10000 (73%)]\tLoss: 0.001211\n",
      "Train Epoch: 5 [7520/10000 (75%)]\tLoss: 0.001112\n",
      "Train Epoch: 5 [7680/10000 (77%)]\tLoss: 0.000922\n",
      "Train Epoch: 5 [7840/10000 (78%)]\tLoss: 0.001073\n",
      "Train Epoch: 5 [8000/10000 (80%)]\tLoss: 0.000919\n",
      "Train Epoch: 5 [8160/10000 (81%)]\tLoss: 0.001019\n",
      "Train Epoch: 5 [8320/10000 (83%)]\tLoss: 0.001042\n",
      "Train Epoch: 5 [8480/10000 (85%)]\tLoss: 0.001086\n",
      "Train Epoch: 5 [8640/10000 (86%)]\tLoss: 0.001093\n",
      "Train Epoch: 5 [8800/10000 (88%)]\tLoss: 0.000971\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 0.001089\n",
      "Train Epoch: 5 [9120/10000 (91%)]\tLoss: 0.001009\n",
      "Train Epoch: 5 [9280/10000 (93%)]\tLoss: 0.001069\n",
      "Train Epoch: 5 [9440/10000 (94%)]\tLoss: 0.001060\n",
      "Train Epoch: 5 [9600/10000 (96%)]\tLoss: 0.000943\n",
      "Train Epoch: 5 [9760/10000 (97%)]\tLoss: 0.000915\n",
      "Train Epoch: 5 [9920/10000 (99%)]\tLoss: 0.001112\n",
      "====> Epoch: 5 Average loss: 0.0011\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 0.001027\n",
      "Train Epoch: 6 [160/10000 (2%)]\tLoss: 0.001063\n",
      "Train Epoch: 6 [320/10000 (3%)]\tLoss: 0.001095\n",
      "Train Epoch: 6 [480/10000 (5%)]\tLoss: 0.001032\n",
      "Train Epoch: 6 [640/10000 (6%)]\tLoss: 0.001022\n",
      "Train Epoch: 6 [800/10000 (8%)]\tLoss: 0.000908\n",
      "Train Epoch: 6 [960/10000 (10%)]\tLoss: 0.000991\n",
      "Train Epoch: 6 [1120/10000 (11%)]\tLoss: 0.001080\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 0.000964\n",
      "Train Epoch: 6 [1440/10000 (14%)]\tLoss: 0.001024\n",
      "Train Epoch: 6 [1600/10000 (16%)]\tLoss: 0.000903\n",
      "Train Epoch: 6 [1760/10000 (18%)]\tLoss: 0.001062\n",
      "Train Epoch: 6 [1920/10000 (19%)]\tLoss: 0.001069\n",
      "Train Epoch: 6 [2080/10000 (21%)]\tLoss: 0.000989\n",
      "Train Epoch: 6 [2240/10000 (22%)]\tLoss: 0.000983\n",
      "Train Epoch: 6 [2400/10000 (24%)]\tLoss: 0.000987\n",
      "Train Epoch: 6 [2560/10000 (26%)]\tLoss: 0.001054\n",
      "Train Epoch: 6 [2720/10000 (27%)]\tLoss: 0.000951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [2880/10000 (29%)]\tLoss: 0.000951\n",
      "Train Epoch: 6 [3040/10000 (30%)]\tLoss: 0.000911\n",
      "Train Epoch: 6 [3200/10000 (32%)]\tLoss: 0.000931\n",
      "Train Epoch: 6 [3360/10000 (34%)]\tLoss: 0.000925\n",
      "Train Epoch: 6 [3520/10000 (35%)]\tLoss: 0.001078\n",
      "Train Epoch: 6 [3680/10000 (37%)]\tLoss: 0.000895\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 0.001051\n",
      "Train Epoch: 6 [4000/10000 (40%)]\tLoss: 0.001097\n",
      "Train Epoch: 6 [4160/10000 (42%)]\tLoss: 0.000944\n",
      "Train Epoch: 6 [4320/10000 (43%)]\tLoss: 0.000894\n",
      "Train Epoch: 6 [4480/10000 (45%)]\tLoss: 0.001041\n",
      "Train Epoch: 6 [4640/10000 (46%)]\tLoss: 0.000944\n",
      "Train Epoch: 6 [4800/10000 (48%)]\tLoss: 0.000943\n",
      "Train Epoch: 6 [4960/10000 (50%)]\tLoss: 0.000897\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 0.000947\n",
      "Train Epoch: 6 [5280/10000 (53%)]\tLoss: 0.001044\n",
      "Train Epoch: 6 [5440/10000 (54%)]\tLoss: 0.000930\n",
      "Train Epoch: 6 [5600/10000 (56%)]\tLoss: 0.000917\n",
      "Train Epoch: 6 [5760/10000 (58%)]\tLoss: 0.001039\n",
      "Train Epoch: 6 [5920/10000 (59%)]\tLoss: 0.001074\n",
      "Train Epoch: 6 [6080/10000 (61%)]\tLoss: 0.000929\n",
      "Train Epoch: 6 [6240/10000 (62%)]\tLoss: 0.000947\n",
      "Train Epoch: 6 [6400/10000 (64%)]\tLoss: 0.000911\n",
      "Train Epoch: 6 [6560/10000 (65%)]\tLoss: 0.001038\n",
      "Train Epoch: 6 [6720/10000 (67%)]\tLoss: 0.001011\n",
      "Train Epoch: 6 [6880/10000 (69%)]\tLoss: 0.000985\n",
      "Train Epoch: 6 [7040/10000 (70%)]\tLoss: 0.000844\n",
      "Train Epoch: 6 [7200/10000 (72%)]\tLoss: 0.001079\n",
      "Train Epoch: 6 [7360/10000 (73%)]\tLoss: 0.000924\n",
      "Train Epoch: 6 [7520/10000 (75%)]\tLoss: 0.000916\n",
      "Train Epoch: 6 [7680/10000 (77%)]\tLoss: 0.000971\n",
      "Train Epoch: 6 [7840/10000 (78%)]\tLoss: 0.001166\n",
      "Train Epoch: 6 [8000/10000 (80%)]\tLoss: 0.000944\n",
      "Train Epoch: 6 [8160/10000 (81%)]\tLoss: 0.000987\n",
      "Train Epoch: 6 [8320/10000 (83%)]\tLoss: 0.000978\n",
      "Train Epoch: 6 [8480/10000 (85%)]\tLoss: 0.001013\n",
      "Train Epoch: 6 [8640/10000 (86%)]\tLoss: 0.001010\n",
      "Train Epoch: 6 [8800/10000 (88%)]\tLoss: 0.000904\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 0.000954\n",
      "Train Epoch: 6 [9120/10000 (91%)]\tLoss: 0.000841\n",
      "Train Epoch: 6 [9280/10000 (93%)]\tLoss: 0.000927\n",
      "Train Epoch: 6 [9440/10000 (94%)]\tLoss: 0.000931\n",
      "Train Epoch: 6 [9600/10000 (96%)]\tLoss: 0.000985\n",
      "Train Epoch: 6 [9760/10000 (97%)]\tLoss: 0.000982\n",
      "Train Epoch: 6 [9920/10000 (99%)]\tLoss: 0.000887\n",
      "====> Epoch: 6 Average loss: 0.0010\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 0.000986\n",
      "Train Epoch: 7 [160/10000 (2%)]\tLoss: 0.001071\n",
      "Train Epoch: 7 [320/10000 (3%)]\tLoss: 0.001017\n",
      "Train Epoch: 7 [480/10000 (5%)]\tLoss: 0.000955\n",
      "Train Epoch: 7 [640/10000 (6%)]\tLoss: 0.000890\n",
      "Train Epoch: 7 [800/10000 (8%)]\tLoss: 0.000865\n",
      "Train Epoch: 7 [960/10000 (10%)]\tLoss: 0.000943\n",
      "Train Epoch: 7 [1120/10000 (11%)]\tLoss: 0.000996\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 0.000939\n",
      "Train Epoch: 7 [1440/10000 (14%)]\tLoss: 0.000973\n",
      "Train Epoch: 7 [1600/10000 (16%)]\tLoss: 0.000904\n",
      "Train Epoch: 7 [1760/10000 (18%)]\tLoss: 0.001019\n",
      "Train Epoch: 7 [1920/10000 (19%)]\tLoss: 0.000934\n",
      "Train Epoch: 7 [2080/10000 (21%)]\tLoss: 0.000932\n",
      "Train Epoch: 7 [2240/10000 (22%)]\tLoss: 0.001007\n",
      "Train Epoch: 7 [2400/10000 (24%)]\tLoss: 0.000907\n",
      "Train Epoch: 7 [2560/10000 (26%)]\tLoss: 0.000974\n",
      "Train Epoch: 7 [2720/10000 (27%)]\tLoss: 0.000865\n",
      "Train Epoch: 7 [2880/10000 (29%)]\tLoss: 0.000899\n",
      "Train Epoch: 7 [3040/10000 (30%)]\tLoss: 0.000901\n",
      "Train Epoch: 7 [3200/10000 (32%)]\tLoss: 0.000982\n",
      "Train Epoch: 7 [3360/10000 (34%)]\tLoss: 0.000960\n",
      "Train Epoch: 7 [3520/10000 (35%)]\tLoss: 0.000953\n",
      "Train Epoch: 7 [3680/10000 (37%)]\tLoss: 0.001024\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 0.000871\n",
      "Train Epoch: 7 [4000/10000 (40%)]\tLoss: 0.000998\n",
      "Train Epoch: 7 [4160/10000 (42%)]\tLoss: 0.000900\n",
      "Train Epoch: 7 [4320/10000 (43%)]\tLoss: 0.000938\n",
      "Train Epoch: 7 [4480/10000 (45%)]\tLoss: 0.000860\n",
      "Train Epoch: 7 [4640/10000 (46%)]\tLoss: 0.000942\n",
      "Train Epoch: 7 [4800/10000 (48%)]\tLoss: 0.000878\n",
      "Train Epoch: 7 [4960/10000 (50%)]\tLoss: 0.000893\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 0.000855\n",
      "Train Epoch: 7 [5280/10000 (53%)]\tLoss: 0.000927\n",
      "Train Epoch: 7 [5440/10000 (54%)]\tLoss: 0.000958\n",
      "Train Epoch: 7 [5600/10000 (56%)]\tLoss: 0.000994\n",
      "Train Epoch: 7 [5760/10000 (58%)]\tLoss: 0.000864\n",
      "Train Epoch: 7 [5920/10000 (59%)]\tLoss: 0.000877\n",
      "Train Epoch: 7 [6080/10000 (61%)]\tLoss: 0.000950\n",
      "Train Epoch: 7 [6240/10000 (62%)]\tLoss: 0.001105\n",
      "Train Epoch: 7 [6400/10000 (64%)]\tLoss: 0.000757\n",
      "Train Epoch: 7 [6560/10000 (65%)]\tLoss: 0.000879\n",
      "Train Epoch: 7 [6720/10000 (67%)]\tLoss: 0.000861\n",
      "Train Epoch: 7 [6880/10000 (69%)]\tLoss: 0.000873\n",
      "Train Epoch: 7 [7040/10000 (70%)]\tLoss: 0.000928\n",
      "Train Epoch: 7 [7200/10000 (72%)]\tLoss: 0.000913\n",
      "Train Epoch: 7 [7360/10000 (73%)]\tLoss: 0.000905\n",
      "Train Epoch: 7 [7520/10000 (75%)]\tLoss: 0.000893\n",
      "Train Epoch: 7 [7680/10000 (77%)]\tLoss: 0.000914\n",
      "Train Epoch: 7 [7840/10000 (78%)]\tLoss: 0.000809\n",
      "Train Epoch: 7 [8000/10000 (80%)]\tLoss: 0.000952\n",
      "Train Epoch: 7 [8160/10000 (81%)]\tLoss: 0.000933\n",
      "Train Epoch: 7 [8320/10000 (83%)]\tLoss: 0.000955\n",
      "Train Epoch: 7 [8480/10000 (85%)]\tLoss: 0.000939\n",
      "Train Epoch: 7 [8640/10000 (86%)]\tLoss: 0.000776\n",
      "Train Epoch: 7 [8800/10000 (88%)]\tLoss: 0.000890\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 0.000834\n",
      "Train Epoch: 7 [9120/10000 (91%)]\tLoss: 0.000938\n",
      "Train Epoch: 7 [9280/10000 (93%)]\tLoss: 0.000857\n",
      "Train Epoch: 7 [9440/10000 (94%)]\tLoss: 0.000869\n",
      "Train Epoch: 7 [9600/10000 (96%)]\tLoss: 0.000746\n",
      "Train Epoch: 7 [9760/10000 (97%)]\tLoss: 0.000850\n",
      "Train Epoch: 7 [9920/10000 (99%)]\tLoss: 0.000888\n",
      "====> Epoch: 7 Average loss: 0.0009\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 0.000944\n",
      "Train Epoch: 8 [160/10000 (2%)]\tLoss: 0.003829\n",
      "Train Epoch: 8 [320/10000 (3%)]\tLoss: 0.134431\n",
      "Train Epoch: 8 [480/10000 (5%)]\tLoss: 0.292182\n",
      "Train Epoch: 8 [640/10000 (6%)]\tLoss: 0.104835\n",
      "Train Epoch: 8 [800/10000 (8%)]\tLoss: 0.069520\n",
      "Train Epoch: 8 [960/10000 (10%)]\tLoss: 0.054163\n",
      "Train Epoch: 8 [1120/10000 (11%)]\tLoss: 0.057592\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 0.037102\n",
      "Train Epoch: 8 [1440/10000 (14%)]\tLoss: 0.016733\n",
      "Train Epoch: 8 [1600/10000 (16%)]\tLoss: 0.008798\n",
      "Train Epoch: 8 [1760/10000 (18%)]\tLoss: 0.007840\n",
      "Train Epoch: 8 [1920/10000 (19%)]\tLoss: 0.005498\n",
      "Train Epoch: 8 [2080/10000 (21%)]\tLoss: 0.003566\n",
      "Train Epoch: 8 [2240/10000 (22%)]\tLoss: 0.002206\n",
      "Train Epoch: 8 [2400/10000 (24%)]\tLoss: 0.001616\n",
      "Train Epoch: 8 [2560/10000 (26%)]\tLoss: 0.001340\n",
      "Train Epoch: 8 [2720/10000 (27%)]\tLoss: 0.001057\n",
      "Train Epoch: 8 [2880/10000 (29%)]\tLoss: 0.001126\n",
      "Train Epoch: 8 [3040/10000 (30%)]\tLoss: 0.000959\n",
      "Train Epoch: 8 [3200/10000 (32%)]\tLoss: 0.001079\n",
      "Train Epoch: 8 [3360/10000 (34%)]\tLoss: 0.001016\n",
      "Train Epoch: 8 [3520/10000 (35%)]\tLoss: 0.000915\n",
      "Train Epoch: 8 [3680/10000 (37%)]\tLoss: 0.000949\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 0.000966\n",
      "Train Epoch: 8 [4000/10000 (40%)]\tLoss: 0.000936\n",
      "Train Epoch: 8 [4160/10000 (42%)]\tLoss: 0.000969\n",
      "Train Epoch: 8 [4320/10000 (43%)]\tLoss: 0.000835\n",
      "Train Epoch: 8 [4480/10000 (45%)]\tLoss: 0.000875\n",
      "Train Epoch: 8 [4640/10000 (46%)]\tLoss: 0.000866\n",
      "Train Epoch: 8 [4800/10000 (48%)]\tLoss: 0.000894\n",
      "Train Epoch: 8 [4960/10000 (50%)]\tLoss: 0.000948\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 0.000864\n",
      "Train Epoch: 8 [5280/10000 (53%)]\tLoss: 0.000862\n",
      "Train Epoch: 8 [5440/10000 (54%)]\tLoss: 0.000801\n",
      "Train Epoch: 8 [5600/10000 (56%)]\tLoss: 0.000891\n",
      "Train Epoch: 8 [5760/10000 (58%)]\tLoss: 0.001053\n",
      "Train Epoch: 8 [5920/10000 (59%)]\tLoss: 0.000944\n",
      "Train Epoch: 8 [6080/10000 (61%)]\tLoss: 0.000934\n",
      "Train Epoch: 8 [6240/10000 (62%)]\tLoss: 0.000971\n",
      "Train Epoch: 8 [6400/10000 (64%)]\tLoss: 0.000799\n",
      "Train Epoch: 8 [6560/10000 (65%)]\tLoss: 0.000768\n",
      "Train Epoch: 8 [6720/10000 (67%)]\tLoss: 0.000945\n",
      "Train Epoch: 8 [6880/10000 (69%)]\tLoss: 0.000861\n",
      "Train Epoch: 8 [7040/10000 (70%)]\tLoss: 0.000794\n",
      "Train Epoch: 8 [7200/10000 (72%)]\tLoss: 0.000825\n",
      "Train Epoch: 8 [7360/10000 (73%)]\tLoss: 0.000842\n",
      "Train Epoch: 8 [7520/10000 (75%)]\tLoss: 0.000897\n",
      "Train Epoch: 8 [7680/10000 (77%)]\tLoss: 0.000805\n",
      "Train Epoch: 8 [7840/10000 (78%)]\tLoss: 0.000823\n",
      "Train Epoch: 8 [8000/10000 (80%)]\tLoss: 0.000870\n",
      "Train Epoch: 8 [8160/10000 (81%)]\tLoss: 0.000830\n",
      "Train Epoch: 8 [8320/10000 (83%)]\tLoss: 0.000805\n",
      "Train Epoch: 8 [8480/10000 (85%)]\tLoss: 0.000838\n",
      "Train Epoch: 8 [8640/10000 (86%)]\tLoss: 0.000834\n",
      "Train Epoch: 8 [8800/10000 (88%)]\tLoss: 0.000819\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 0.000788\n",
      "Train Epoch: 8 [9120/10000 (91%)]\tLoss: 0.000867\n",
      "Train Epoch: 8 [9280/10000 (93%)]\tLoss: 0.000840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [9440/10000 (94%)]\tLoss: 0.000782\n",
      "Train Epoch: 8 [9600/10000 (96%)]\tLoss: 0.000794\n",
      "Train Epoch: 8 [9760/10000 (97%)]\tLoss: 0.000826\n",
      "Train Epoch: 8 [9920/10000 (99%)]\tLoss: 0.000794\n",
      "====> Epoch: 8 Average loss: 0.0156\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 0.000760\n",
      "Train Epoch: 9 [160/10000 (2%)]\tLoss: 0.000836\n",
      "Train Epoch: 9 [320/10000 (3%)]\tLoss: 0.000816\n",
      "Train Epoch: 9 [480/10000 (5%)]\tLoss: 0.000841\n",
      "Train Epoch: 9 [640/10000 (6%)]\tLoss: 0.000906\n",
      "Train Epoch: 9 [800/10000 (8%)]\tLoss: 0.000784\n",
      "Train Epoch: 9 [960/10000 (10%)]\tLoss: 0.000831\n",
      "Train Epoch: 9 [1120/10000 (11%)]\tLoss: 0.000887\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 0.000756\n",
      "Train Epoch: 9 [1440/10000 (14%)]\tLoss: 0.000774\n",
      "Train Epoch: 9 [1600/10000 (16%)]\tLoss: 0.000828\n",
      "Train Epoch: 9 [1760/10000 (18%)]\tLoss: 0.000766\n",
      "Train Epoch: 9 [1920/10000 (19%)]\tLoss: 0.000799\n",
      "Train Epoch: 9 [2080/10000 (21%)]\tLoss: 0.000885\n",
      "Train Epoch: 9 [2240/10000 (22%)]\tLoss: 0.000796\n",
      "Train Epoch: 9 [2400/10000 (24%)]\tLoss: 0.000793\n",
      "Train Epoch: 9 [2560/10000 (26%)]\tLoss: 0.000946\n",
      "Train Epoch: 9 [2720/10000 (27%)]\tLoss: 0.000835\n",
      "Train Epoch: 9 [2880/10000 (29%)]\tLoss: 0.000800\n",
      "Train Epoch: 9 [3040/10000 (30%)]\tLoss: 0.000835\n",
      "Train Epoch: 9 [3200/10000 (32%)]\tLoss: 0.000905\n",
      "Train Epoch: 9 [3360/10000 (34%)]\tLoss: 0.000781\n",
      "Train Epoch: 9 [3520/10000 (35%)]\tLoss: 0.000792\n",
      "Train Epoch: 9 [3680/10000 (37%)]\tLoss: 0.000797\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 0.000742\n",
      "Train Epoch: 9 [4000/10000 (40%)]\tLoss: 0.000758\n",
      "Train Epoch: 9 [4160/10000 (42%)]\tLoss: 0.000747\n",
      "Train Epoch: 9 [4320/10000 (43%)]\tLoss: 0.000808\n",
      "Train Epoch: 9 [4480/10000 (45%)]\tLoss: 0.000759\n",
      "Train Epoch: 9 [4640/10000 (46%)]\tLoss: 0.000770\n",
      "Train Epoch: 9 [4800/10000 (48%)]\tLoss: 0.000874\n",
      "Train Epoch: 9 [4960/10000 (50%)]\tLoss: 0.000792\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 0.000784\n",
      "Train Epoch: 9 [5280/10000 (53%)]\tLoss: 0.000845\n",
      "Train Epoch: 9 [5440/10000 (54%)]\tLoss: 0.000730\n",
      "Train Epoch: 9 [5600/10000 (56%)]\tLoss: 0.000762\n",
      "Train Epoch: 9 [5760/10000 (58%)]\tLoss: 0.000809\n",
      "Train Epoch: 9 [5920/10000 (59%)]\tLoss: 0.000822\n",
      "Train Epoch: 9 [6080/10000 (61%)]\tLoss: 0.000901\n",
      "Train Epoch: 9 [6240/10000 (62%)]\tLoss: 0.000813\n",
      "Train Epoch: 9 [6400/10000 (64%)]\tLoss: 0.000789\n",
      "Train Epoch: 9 [6560/10000 (65%)]\tLoss: 0.000797\n",
      "Train Epoch: 9 [6720/10000 (67%)]\tLoss: 0.000870\n",
      "Train Epoch: 9 [6880/10000 (69%)]\tLoss: 0.000762\n",
      "Train Epoch: 9 [7040/10000 (70%)]\tLoss: 0.000708\n",
      "Train Epoch: 9 [7200/10000 (72%)]\tLoss: 0.000795\n",
      "Train Epoch: 9 [7360/10000 (73%)]\tLoss: 0.000843\n",
      "Train Epoch: 9 [7520/10000 (75%)]\tLoss: 0.000789\n",
      "Train Epoch: 9 [7680/10000 (77%)]\tLoss: 0.000833\n",
      "Train Epoch: 9 [7840/10000 (78%)]\tLoss: 0.000788\n",
      "Train Epoch: 9 [8000/10000 (80%)]\tLoss: 0.000798\n",
      "Train Epoch: 9 [8160/10000 (81%)]\tLoss: 0.000776\n",
      "Train Epoch: 9 [8320/10000 (83%)]\tLoss: 0.000701\n",
      "Train Epoch: 9 [8480/10000 (85%)]\tLoss: 0.000747\n",
      "Train Epoch: 9 [8640/10000 (86%)]\tLoss: 0.000783\n",
      "Train Epoch: 9 [8800/10000 (88%)]\tLoss: 0.000746\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 0.000759\n",
      "Train Epoch: 9 [9120/10000 (91%)]\tLoss: 0.000771\n",
      "Train Epoch: 9 [9280/10000 (93%)]\tLoss: 0.000843\n",
      "Train Epoch: 9 [9440/10000 (94%)]\tLoss: 0.000716\n",
      "Train Epoch: 9 [9600/10000 (96%)]\tLoss: 0.000725\n",
      "Train Epoch: 9 [9760/10000 (97%)]\tLoss: 0.000786\n",
      "Train Epoch: 9 [9920/10000 (99%)]\tLoss: 0.000860\n",
      "====> Epoch: 9 Average loss: 0.0008\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 0.000719\n",
      "Train Epoch: 10 [160/10000 (2%)]\tLoss: 0.000879\n",
      "Train Epoch: 10 [320/10000 (3%)]\tLoss: 0.000740\n",
      "Train Epoch: 10 [480/10000 (5%)]\tLoss: 0.000787\n",
      "Train Epoch: 10 [640/10000 (6%)]\tLoss: 0.000698\n",
      "Train Epoch: 10 [800/10000 (8%)]\tLoss: 0.000753\n",
      "Train Epoch: 10 [960/10000 (10%)]\tLoss: 0.000757\n",
      "Train Epoch: 10 [1120/10000 (11%)]\tLoss: 0.000768\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 0.000731\n",
      "Train Epoch: 10 [1440/10000 (14%)]\tLoss: 0.000731\n",
      "Train Epoch: 10 [1600/10000 (16%)]\tLoss: 0.000864\n",
      "Train Epoch: 10 [1760/10000 (18%)]\tLoss: 0.000757\n",
      "Train Epoch: 10 [1920/10000 (19%)]\tLoss: 0.000768\n",
      "Train Epoch: 10 [2080/10000 (21%)]\tLoss: 0.000783\n",
      "Train Epoch: 10 [2240/10000 (22%)]\tLoss: 0.000701\n",
      "Train Epoch: 10 [2400/10000 (24%)]\tLoss: 0.000826\n",
      "Train Epoch: 10 [2560/10000 (26%)]\tLoss: 0.000817\n",
      "Train Epoch: 10 [2720/10000 (27%)]\tLoss: 0.000790\n",
      "Train Epoch: 10 [2880/10000 (29%)]\tLoss: 0.000766\n",
      "Train Epoch: 10 [3040/10000 (30%)]\tLoss: 0.000761\n",
      "Train Epoch: 10 [3200/10000 (32%)]\tLoss: 0.000809\n",
      "Train Epoch: 10 [3360/10000 (34%)]\tLoss: 0.000802\n",
      "Train Epoch: 10 [3520/10000 (35%)]\tLoss: 0.000764\n",
      "Train Epoch: 10 [3680/10000 (37%)]\tLoss: 0.000707\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 0.000737\n",
      "Train Epoch: 10 [4000/10000 (40%)]\tLoss: 0.000807\n",
      "Train Epoch: 10 [4160/10000 (42%)]\tLoss: 0.000738\n",
      "Train Epoch: 10 [4320/10000 (43%)]\tLoss: 0.000723\n",
      "Train Epoch: 10 [4480/10000 (45%)]\tLoss: 0.000820\n",
      "Train Epoch: 10 [4640/10000 (46%)]\tLoss: 0.000759\n",
      "Train Epoch: 10 [4800/10000 (48%)]\tLoss: 0.000623\n",
      "Train Epoch: 10 [4960/10000 (50%)]\tLoss: 0.000710\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 0.000685\n",
      "Train Epoch: 10 [5280/10000 (53%)]\tLoss: 0.000747\n",
      "Train Epoch: 10 [5440/10000 (54%)]\tLoss: 0.000684\n",
      "Train Epoch: 10 [5600/10000 (56%)]\tLoss: 0.000696\n",
      "Train Epoch: 10 [5760/10000 (58%)]\tLoss: 0.000707\n",
      "Train Epoch: 10 [5920/10000 (59%)]\tLoss: 0.000732\n",
      "Train Epoch: 10 [6080/10000 (61%)]\tLoss: 0.000804\n",
      "Train Epoch: 10 [6240/10000 (62%)]\tLoss: 0.000775\n",
      "Train Epoch: 10 [6400/10000 (64%)]\tLoss: 0.000747\n",
      "Train Epoch: 10 [6560/10000 (65%)]\tLoss: 0.000615\n",
      "Train Epoch: 10 [6720/10000 (67%)]\tLoss: 0.000733\n",
      "Train Epoch: 10 [6880/10000 (69%)]\tLoss: 0.000666\n",
      "Train Epoch: 10 [7040/10000 (70%)]\tLoss: 0.000784\n",
      "Train Epoch: 10 [7200/10000 (72%)]\tLoss: 0.000683\n",
      "Train Epoch: 10 [7360/10000 (73%)]\tLoss: 0.000727\n",
      "Train Epoch: 10 [7520/10000 (75%)]\tLoss: 0.000727\n",
      "Train Epoch: 10 [7680/10000 (77%)]\tLoss: 0.000691\n",
      "Train Epoch: 10 [7840/10000 (78%)]\tLoss: 0.000677\n",
      "Train Epoch: 10 [8000/10000 (80%)]\tLoss: 0.000756\n",
      "Train Epoch: 10 [8160/10000 (81%)]\tLoss: 0.000604\n",
      "Train Epoch: 10 [8320/10000 (83%)]\tLoss: 0.000719\n",
      "Train Epoch: 10 [8480/10000 (85%)]\tLoss: 0.000697\n",
      "Train Epoch: 10 [8640/10000 (86%)]\tLoss: 0.000694\n",
      "Train Epoch: 10 [8800/10000 (88%)]\tLoss: 0.000724\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 0.000683\n",
      "Train Epoch: 10 [9120/10000 (91%)]\tLoss: 0.000704\n",
      "Train Epoch: 10 [9280/10000 (93%)]\tLoss: 0.000767\n",
      "Train Epoch: 10 [9440/10000 (94%)]\tLoss: 0.000735\n",
      "Train Epoch: 10 [9600/10000 (96%)]\tLoss: 0.000649\n",
      "Train Epoch: 10 [9760/10000 (97%)]\tLoss: 0.000667\n",
      "Train Epoch: 10 [9920/10000 (99%)]\tLoss: 0.000732\n",
      "====> Epoch: 10 Average loss: 0.0007\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 0.000758\n",
      "Train Epoch: 11 [160/10000 (2%)]\tLoss: 0.000709\n",
      "Train Epoch: 11 [320/10000 (3%)]\tLoss: 0.000642\n",
      "Train Epoch: 11 [480/10000 (5%)]\tLoss: 0.000735\n",
      "Train Epoch: 11 [640/10000 (6%)]\tLoss: 0.000723\n",
      "Train Epoch: 11 [800/10000 (8%)]\tLoss: 0.000784\n",
      "Train Epoch: 11 [960/10000 (10%)]\tLoss: 0.000750\n",
      "Train Epoch: 11 [1120/10000 (11%)]\tLoss: 0.000677\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 0.000857\n",
      "Train Epoch: 11 [1440/10000 (14%)]\tLoss: 0.000733\n",
      "Train Epoch: 11 [1600/10000 (16%)]\tLoss: 0.000749\n",
      "Train Epoch: 11 [1760/10000 (18%)]\tLoss: 0.000630\n",
      "Train Epoch: 11 [1920/10000 (19%)]\tLoss: 0.000701\n",
      "Train Epoch: 11 [2080/10000 (21%)]\tLoss: 0.000766\n",
      "Train Epoch: 11 [2240/10000 (22%)]\tLoss: 0.000787\n",
      "Train Epoch: 11 [2400/10000 (24%)]\tLoss: 0.000736\n",
      "Train Epoch: 11 [2560/10000 (26%)]\tLoss: 0.000658\n",
      "Train Epoch: 11 [2720/10000 (27%)]\tLoss: 0.000684\n",
      "Train Epoch: 11 [2880/10000 (29%)]\tLoss: 0.000728\n",
      "Train Epoch: 11 [3040/10000 (30%)]\tLoss: 0.000677\n",
      "Train Epoch: 11 [3200/10000 (32%)]\tLoss: 0.000786\n",
      "Train Epoch: 11 [3360/10000 (34%)]\tLoss: 0.000685\n",
      "Train Epoch: 11 [3520/10000 (35%)]\tLoss: 0.000688\n",
      "Train Epoch: 11 [3680/10000 (37%)]\tLoss: 0.000762\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 0.000699\n",
      "Train Epoch: 11 [4000/10000 (40%)]\tLoss: 0.000686\n",
      "Train Epoch: 11 [4160/10000 (42%)]\tLoss: 0.000671\n",
      "Train Epoch: 11 [4320/10000 (43%)]\tLoss: 0.000681\n",
      "Train Epoch: 11 [4480/10000 (45%)]\tLoss: 0.000783\n",
      "Train Epoch: 11 [4640/10000 (46%)]\tLoss: 0.000766\n",
      "Train Epoch: 11 [4800/10000 (48%)]\tLoss: 0.000731\n",
      "Train Epoch: 11 [4960/10000 (50%)]\tLoss: 0.000631\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 0.000698\n",
      "Train Epoch: 11 [5280/10000 (53%)]\tLoss: 0.000641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [5440/10000 (54%)]\tLoss: 0.000701\n",
      "Train Epoch: 11 [5600/10000 (56%)]\tLoss: 0.000638\n",
      "Train Epoch: 11 [5760/10000 (58%)]\tLoss: 0.000751\n",
      "Train Epoch: 11 [5920/10000 (59%)]\tLoss: 0.000730\n",
      "Train Epoch: 11 [6080/10000 (61%)]\tLoss: 0.000695\n",
      "Train Epoch: 11 [6240/10000 (62%)]\tLoss: 0.000649\n",
      "Train Epoch: 11 [6400/10000 (64%)]\tLoss: 0.000693\n",
      "Train Epoch: 11 [6560/10000 (65%)]\tLoss: 0.000758\n",
      "Train Epoch: 11 [6720/10000 (67%)]\tLoss: 0.000754\n",
      "Train Epoch: 11 [6880/10000 (69%)]\tLoss: 0.000655\n",
      "Train Epoch: 11 [7040/10000 (70%)]\tLoss: 0.000633\n",
      "Train Epoch: 11 [7200/10000 (72%)]\tLoss: 0.000657\n",
      "Train Epoch: 11 [7360/10000 (73%)]\tLoss: 0.000670\n",
      "Train Epoch: 11 [7520/10000 (75%)]\tLoss: 0.000793\n",
      "Train Epoch: 11 [7680/10000 (77%)]\tLoss: 0.000736\n",
      "Train Epoch: 11 [7840/10000 (78%)]\tLoss: 0.000749\n",
      "Train Epoch: 11 [8000/10000 (80%)]\tLoss: 0.000637\n",
      "Train Epoch: 11 [8160/10000 (81%)]\tLoss: 0.000674\n",
      "Train Epoch: 11 [8320/10000 (83%)]\tLoss: 0.000559\n",
      "Train Epoch: 11 [8480/10000 (85%)]\tLoss: 0.000791\n",
      "Train Epoch: 11 [8640/10000 (86%)]\tLoss: 0.000877\n",
      "Train Epoch: 11 [8800/10000 (88%)]\tLoss: 0.001053\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 0.000733\n",
      "Train Epoch: 11 [9120/10000 (91%)]\tLoss: 0.000752\n",
      "Train Epoch: 11 [9280/10000 (93%)]\tLoss: 0.000772\n",
      "Train Epoch: 11 [9440/10000 (94%)]\tLoss: 0.000764\n",
      "Train Epoch: 11 [9600/10000 (96%)]\tLoss: 0.000702\n",
      "Train Epoch: 11 [9760/10000 (97%)]\tLoss: 0.000707\n",
      "Train Epoch: 11 [9920/10000 (99%)]\tLoss: 0.000647\n",
      "====> Epoch: 11 Average loss: 0.0007\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 0.000700\n",
      "Train Epoch: 12 [160/10000 (2%)]\tLoss: 0.000761\n",
      "Train Epoch: 12 [320/10000 (3%)]\tLoss: 0.000647\n",
      "Train Epoch: 12 [480/10000 (5%)]\tLoss: 0.000878\n",
      "Train Epoch: 12 [640/10000 (6%)]\tLoss: 0.001112\n",
      "Train Epoch: 12 [800/10000 (8%)]\tLoss: 0.001594\n",
      "Train Epoch: 12 [960/10000 (10%)]\tLoss: 0.001169\n",
      "Train Epoch: 12 [1120/10000 (11%)]\tLoss: 0.000740\n",
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 0.000719\n",
      "Train Epoch: 12 [1440/10000 (14%)]\tLoss: 0.000710\n",
      "Train Epoch: 12 [1600/10000 (16%)]\tLoss: 0.000683\n",
      "Train Epoch: 12 [1760/10000 (18%)]\tLoss: 0.000645\n",
      "Train Epoch: 12 [1920/10000 (19%)]\tLoss: 0.000649\n",
      "Train Epoch: 12 [2080/10000 (21%)]\tLoss: 0.000751\n",
      "Train Epoch: 12 [2240/10000 (22%)]\tLoss: 0.000653\n",
      "Train Epoch: 12 [2400/10000 (24%)]\tLoss: 0.000720\n",
      "Train Epoch: 12 [2560/10000 (26%)]\tLoss: 0.000652\n",
      "Train Epoch: 12 [2720/10000 (27%)]\tLoss: 0.000748\n",
      "Train Epoch: 12 [2880/10000 (29%)]\tLoss: 0.000679\n",
      "Train Epoch: 12 [3040/10000 (30%)]\tLoss: 0.000694\n",
      "Train Epoch: 12 [3200/10000 (32%)]\tLoss: 0.000868\n",
      "Train Epoch: 12 [3360/10000 (34%)]\tLoss: 0.000713\n",
      "Train Epoch: 12 [3520/10000 (35%)]\tLoss: 0.000742\n",
      "Train Epoch: 12 [3680/10000 (37%)]\tLoss: 0.000730\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 0.000821\n",
      "Train Epoch: 12 [4000/10000 (40%)]\tLoss: 0.000747\n",
      "Train Epoch: 12 [4160/10000 (42%)]\tLoss: 0.000795\n",
      "Train Epoch: 12 [4320/10000 (43%)]\tLoss: 0.000790\n",
      "Train Epoch: 12 [4480/10000 (45%)]\tLoss: 0.000841\n",
      "Train Epoch: 12 [4640/10000 (46%)]\tLoss: 0.000742\n",
      "Train Epoch: 12 [4800/10000 (48%)]\tLoss: 0.000734\n",
      "Train Epoch: 12 [4960/10000 (50%)]\tLoss: 0.000745\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 0.000667\n",
      "Train Epoch: 12 [5280/10000 (53%)]\tLoss: 0.000581\n",
      "Train Epoch: 12 [5440/10000 (54%)]\tLoss: 0.000681\n",
      "Train Epoch: 12 [5600/10000 (56%)]\tLoss: 0.000707\n",
      "Train Epoch: 12 [5760/10000 (58%)]\tLoss: 0.000774\n",
      "Train Epoch: 12 [5920/10000 (59%)]\tLoss: 0.001002\n",
      "Train Epoch: 12 [6080/10000 (61%)]\tLoss: 0.001545\n",
      "Train Epoch: 12 [6240/10000 (62%)]\tLoss: 0.001467\n",
      "Train Epoch: 12 [6400/10000 (64%)]\tLoss: 0.000685\n",
      "Train Epoch: 12 [6560/10000 (65%)]\tLoss: 0.000795\n",
      "Train Epoch: 12 [6720/10000 (67%)]\tLoss: 0.000627\n",
      "Train Epoch: 12 [6880/10000 (69%)]\tLoss: 0.000747\n",
      "Train Epoch: 12 [7040/10000 (70%)]\tLoss: 0.000726\n",
      "Train Epoch: 12 [7200/10000 (72%)]\tLoss: 0.000648\n",
      "Train Epoch: 12 [7360/10000 (73%)]\tLoss: 0.000665\n",
      "Train Epoch: 12 [7520/10000 (75%)]\tLoss: 0.000649\n",
      "Train Epoch: 12 [7680/10000 (77%)]\tLoss: 0.000660\n",
      "Train Epoch: 12 [7840/10000 (78%)]\tLoss: 0.000681\n",
      "Train Epoch: 12 [8000/10000 (80%)]\tLoss: 0.000827\n",
      "Train Epoch: 12 [8160/10000 (81%)]\tLoss: 0.000930\n",
      "Train Epoch: 12 [8320/10000 (83%)]\tLoss: 0.000764\n",
      "Train Epoch: 12 [8480/10000 (85%)]\tLoss: 0.000725\n",
      "Train Epoch: 12 [8640/10000 (86%)]\tLoss: 0.000670\n",
      "Train Epoch: 12 [8800/10000 (88%)]\tLoss: 0.000718\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 0.000673\n",
      "Train Epoch: 12 [9120/10000 (91%)]\tLoss: 0.000633\n",
      "Train Epoch: 12 [9280/10000 (93%)]\tLoss: 0.000650\n",
      "Train Epoch: 12 [9440/10000 (94%)]\tLoss: 0.000665\n",
      "Train Epoch: 12 [9600/10000 (96%)]\tLoss: 0.000670\n",
      "Train Epoch: 12 [9760/10000 (97%)]\tLoss: 0.000640\n",
      "Train Epoch: 12 [9920/10000 (99%)]\tLoss: 0.000668\n",
      "====> Epoch: 12 Average loss: 0.0008\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 0.000631\n",
      "Train Epoch: 13 [160/10000 (2%)]\tLoss: 0.001823\n",
      "Train Epoch: 13 [320/10000 (3%)]\tLoss: 0.000960\n",
      "Train Epoch: 13 [480/10000 (5%)]\tLoss: 0.001015\n",
      "Train Epoch: 13 [640/10000 (6%)]\tLoss: 0.000601\n",
      "Train Epoch: 13 [800/10000 (8%)]\tLoss: 0.000892\n",
      "Train Epoch: 13 [960/10000 (10%)]\tLoss: 0.000818\n",
      "Train Epoch: 13 [1120/10000 (11%)]\tLoss: 0.000662\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 0.000616\n",
      "Train Epoch: 13 [1440/10000 (14%)]\tLoss: 0.000642\n",
      "Train Epoch: 13 [1600/10000 (16%)]\tLoss: 0.000690\n",
      "Train Epoch: 13 [1760/10000 (18%)]\tLoss: 0.000630\n",
      "Train Epoch: 13 [1920/10000 (19%)]\tLoss: 0.000709\n",
      "Train Epoch: 13 [2080/10000 (21%)]\tLoss: 0.000641\n",
      "Train Epoch: 13 [2240/10000 (22%)]\tLoss: 0.000708\n",
      "Train Epoch: 13 [2400/10000 (24%)]\tLoss: 0.000716\n",
      "Train Epoch: 13 [2560/10000 (26%)]\tLoss: 0.000727\n",
      "Train Epoch: 13 [2720/10000 (27%)]\tLoss: 0.000868\n",
      "Train Epoch: 13 [2880/10000 (29%)]\tLoss: 0.001242\n",
      "Train Epoch: 13 [3040/10000 (30%)]\tLoss: 0.001706\n",
      "Train Epoch: 13 [3200/10000 (32%)]\tLoss: 0.000859\n",
      "Train Epoch: 13 [3360/10000 (34%)]\tLoss: 0.000803\n",
      "Train Epoch: 13 [3520/10000 (35%)]\tLoss: 0.000734\n",
      "Train Epoch: 13 [3680/10000 (37%)]\tLoss: 0.000613\n",
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 0.000640\n",
      "Train Epoch: 13 [4000/10000 (40%)]\tLoss: 0.000606\n",
      "Train Epoch: 13 [4160/10000 (42%)]\tLoss: 0.000625\n",
      "Train Epoch: 13 [4320/10000 (43%)]\tLoss: 0.000651\n",
      "Train Epoch: 13 [4480/10000 (45%)]\tLoss: 0.000630\n",
      "Train Epoch: 13 [4640/10000 (46%)]\tLoss: 0.000590\n",
      "Train Epoch: 13 [4800/10000 (48%)]\tLoss: 0.000586\n",
      "Train Epoch: 13 [4960/10000 (50%)]\tLoss: 0.000654\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 0.000639\n",
      "Train Epoch: 13 [5280/10000 (53%)]\tLoss: 0.000718\n",
      "Train Epoch: 13 [5440/10000 (54%)]\tLoss: 0.000603\n",
      "Train Epoch: 13 [5600/10000 (56%)]\tLoss: 0.000640\n",
      "Train Epoch: 13 [5760/10000 (58%)]\tLoss: 0.000631\n",
      "Train Epoch: 13 [5920/10000 (59%)]\tLoss: 0.000655\n",
      "Train Epoch: 13 [6080/10000 (61%)]\tLoss: 0.000530\n",
      "Train Epoch: 13 [6240/10000 (62%)]\tLoss: 0.000606\n",
      "Train Epoch: 13 [6400/10000 (64%)]\tLoss: 0.000656\n",
      "Train Epoch: 13 [6560/10000 (65%)]\tLoss: 0.000661\n",
      "Train Epoch: 13 [6720/10000 (67%)]\tLoss: 0.000709\n",
      "Train Epoch: 13 [6880/10000 (69%)]\tLoss: 0.000828\n",
      "Train Epoch: 13 [7040/10000 (70%)]\tLoss: 0.000951\n",
      "Train Epoch: 13 [7200/10000 (72%)]\tLoss: 0.001396\n",
      "Train Epoch: 13 [7360/10000 (73%)]\tLoss: 0.001327\n",
      "Train Epoch: 13 [7520/10000 (75%)]\tLoss: 0.000605\n",
      "Train Epoch: 13 [7680/10000 (77%)]\tLoss: 0.000742\n",
      "Train Epoch: 13 [7840/10000 (78%)]\tLoss: 0.000634\n",
      "Train Epoch: 13 [8000/10000 (80%)]\tLoss: 0.000634\n",
      "Train Epoch: 13 [8160/10000 (81%)]\tLoss: 0.000676\n",
      "Train Epoch: 13 [8320/10000 (83%)]\tLoss: 0.000541\n",
      "Train Epoch: 13 [8480/10000 (85%)]\tLoss: 0.000613\n",
      "Train Epoch: 13 [8640/10000 (86%)]\tLoss: 0.000557\n",
      "Train Epoch: 13 [8800/10000 (88%)]\tLoss: 0.000618\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 0.000597\n",
      "Train Epoch: 13 [9120/10000 (91%)]\tLoss: 0.000563\n",
      "Train Epoch: 13 [9280/10000 (93%)]\tLoss: 0.000709\n",
      "Train Epoch: 13 [9440/10000 (94%)]\tLoss: 0.000696\n",
      "Train Epoch: 13 [9600/10000 (96%)]\tLoss: 0.000910\n",
      "Train Epoch: 13 [9760/10000 (97%)]\tLoss: 0.001956\n",
      "Train Epoch: 13 [9920/10000 (99%)]\tLoss: 0.001055\n",
      "====> Epoch: 13 Average loss: 0.0008\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 0.000728\n"
     ]
    }
   ],
   "source": [
    "# Loading WT model and setting to eval for inference\n",
    "wt_model = VAE()\n",
    "wt_model.load_state_dict(torch.load('./wtvae_2wt_models/wtvae_epoch88.pth'))\n",
    "wt_model.to('cuda:1')\n",
    "wt_model.eval()\n",
    "iwt_model = LearnIWT(device='cuda:0').to('cuda:0')\n",
    "\n",
    "train_losses = []\n",
    "gc.collect()\n",
    "EPOCHS = 100\n",
    "\n",
    "optimizer = optim.Adam(iwt_model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch, iwt_model, optimizer, train_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        iwt_model.eval()\n",
    "\n",
    "        for data in sample_loader:\n",
    "            if CUDA:\n",
    "                data0 = data.to('cuda:0')\n",
    "                data1 = data.to('cuda:1')\n",
    "            \n",
    "            z_sample = torch.randn(data.shape[0],100).to('cuda:0')\n",
    "            \n",
    "            Y = wt_model(data1)[0].to('cuda:0')\n",
    "            mu, var = iwt_model.encode(data0, Y)\n",
    "            x_hat = iwt_model.decode(Y, mu)\n",
    "            x_sample = iwt_model.decode(Y, z_sample)\n",
    "            \n",
    "            save_image(x_hat.cpu(), './image_samples/celeba_dsvae_1/sample_recon' + str(epoch) + '.png') \n",
    "            save_image(x_sample.cpu(), './image_samples/celeba_dsvae_1/sample_z' + str(epoch) + '.png')\n",
    "            save_image(Y.cpu(), './image_samples/celeba_dsvae_1/sample_y' + str(epoch) + '.png') \n",
    "            save_image(data.cpu(), './image_samples/celeba_dsvae_1/sample' + str(epoch) + '.png')  \n",
    "    \n",
    "    torch.save(iwt_model.state_dict(), './models/iwtvae64_models_rest0/iwtvae_epoch{}.pth'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wmlce-1.6.2",
   "language": "python",
   "name": "wmlce-1.6.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
