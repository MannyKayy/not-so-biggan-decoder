{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folder called celeba in home dir where reconstructed images will be stored\n",
    "#Considered only 100000 images for training\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebaDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, img_list, WT=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_list = img_list\n",
    "        self.WT = WT\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.root_dir, self.img_list[idx]))\n",
    "        img = np.array(img)\n",
    "        img = img / 255\n",
    "        img = torch.from_numpy(img.transpose(2,0,1)).float()\n",
    "        \n",
    "        # Returning both original image and WT image if self.WT\n",
    "        if self.WT:\n",
    "#             img_wt = torch.from_numpy(img.transpose(2,0,1)).float()\n",
    "            img_wt = wt(img_wt.unsqueeze(1)).squeeze()\n",
    "\n",
    "            return img, img_wt\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors. numpy image: H x W x C, torch image: C X H X W\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, image, invert_arrays=True):\n",
    "\n",
    "        if invert_arrays:\n",
    "            image = image.transpose((2, 0, 1))[:,:h_img*2,:w_img*2]\n",
    "\n",
    "        return torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
