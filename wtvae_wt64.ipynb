{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folder called celeba in home dir where reconstructed images will be stored\n",
    "#Considered only 100000 images for training\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as utils\n",
    "import gc\n",
    "import pywt\n",
    "import IPython\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "no_of_sample = 1\n",
    "CUDA = True\n",
    "BATCH_SIZE = 32\n",
    "LOG_INTERVAL = 5\n",
    "h_img = 64\n",
    "w_img = 64\n",
    "flat = h_img*w_img*3\n",
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=pywt.Wavelet('bior2.2')\n",
    "\n",
    "\n",
    "dec_hi = torch.Tensor(w.dec_hi[::-1]).cuda() \n",
    "dec_lo = torch.Tensor(w.dec_lo[::-1]).cuda()\n",
    "rec_hi = torch.Tensor(w.rec_hi).cuda()\n",
    "rec_lo = torch.Tensor(w.rec_lo).cuda()\n",
    "dec_hi_cpu = torch.Tensor(w.dec_hi[::-1]).clone().cpu()\n",
    "dec_lo_cpu = torch.Tensor(w.dec_lo[::-1]).clone().cpu()\n",
    "rec_hi_cpu = torch.Tensor(w.rec_hi).clone().cpu()\n",
    "rec_lo_cpu = torch.Tensor(w.rec_lo).clone().cpu()\n",
    "\n",
    "\n",
    "filters = torch.stack([dec_lo_cpu.unsqueeze(0)*dec_lo_cpu.unsqueeze(1),\n",
    "                       dec_lo_cpu.unsqueeze(0)*dec_hi_cpu.unsqueeze(1),\n",
    "                       dec_hi_cpu.unsqueeze(0)*dec_lo_cpu.unsqueeze(1),\n",
    "                       dec_hi_cpu.unsqueeze(0)*dec_hi_cpu.unsqueeze(1)], dim=0)\n",
    "\n",
    "inv_filters = torch.stack([rec_lo.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                           rec_lo.unsqueeze(0)*rec_hi.unsqueeze(1),\n",
    "                           rec_hi.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                           rec_hi.unsqueeze(0)*rec_hi.unsqueeze(1)], dim=0)\n",
    "\n",
    "\n",
    "def wt(vimg, levels=1):\n",
    "    h = vimg.size(2)\n",
    "    w = vimg.size(3)\n",
    "#     print(vimg.size())\n",
    "    padded = torch.nn.functional.pad(vimg,(2,2,2,2))\n",
    "    res = torch.nn.functional.conv2d(padded, Variable(filters[:,None]),stride=2)\n",
    "    if levels>1:\n",
    "        res[:,:1] = wt(res[:,:1],levels-1)\n",
    "        res[:,:1,32:,:] = res[:,:1,32:,:]*1.\n",
    "        res[:,:1,:,32:] = res[:,:1,:,32:]*1.\n",
    "        res[:,1:] = res[:,1:]*1.\n",
    "    res = res.view(-1,2,h//2,w//2).transpose(1,2).contiguous().view(-1,1,h,w)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def iwt(vres, levels=1):\n",
    "    h = vres.size(2)\n",
    "    w = vres.size(3)\n",
    "    res = vres.contiguous().view(-1,h//2,2,w//2).transpose(1,2).contiguous().view(-1,4,h//2,w//2).clone()\n",
    "    if levels>1:\n",
    "        res[:,:1] = iwt(res[:,:1], levels=levels-1)\n",
    "    res = torch.nn.functional.conv_transpose2d(res, Variable(inv_filters[:,None]),stride=2)\n",
    "    res = res[:,:,2:-2,2:-2] #removing padding\n",
    "#     print(res.shape)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebaDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, img_list, WT=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_list = img_list\n",
    "        self.WT = WT\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.root_dir, self.img_list[idx]))\n",
    "        img = np.array(img)\n",
    "        img = img / 255\n",
    "        img = torch.from_numpy(img.transpose(2,0,1)).float()\n",
    "        \n",
    "        # Returning both original image and WT image if self.WT\n",
    "        if self.WT:\n",
    "#             img_wt = torch.from_numpy(img.transpose(2,0,1)).float()\n",
    "            img_wt = wt(img_wt.unsqueeze(1)).squeeze()\n",
    "\n",
    "            return img, img_wt\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors. numpy image: H x W x C, torch image: C X H X W\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, image, invert_arrays=True):\n",
    "\n",
    "        if invert_arrays:\n",
    "            image = image.transpose((2, 0, 1))[:,:h_img*2,:w_img*2]\n",
    "\n",
    "        return torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO29aZBc13UmeM57uWfthapCYSNWEtxAkKIoUQu1a2RJltpheVp2T4+6rWhOOOwJeaY7WlJ7YqJ7YnrC8o+2+0eHO9iWR4oOt2W5vUittrahSEuiRIrgDhAEARI7CijUXrlnvnfnRyXe+c6pykJJABKU8n4RCNyse/Plffe9l3nO/c75DjvnyMPD4xcfwc2egIeHR3fgH3YPjx6Bf9g9PHoE/mH38OgR+Ifdw6NH4B92D48ewTU97Mz8IWY+xswnmPlz12tSHh4e1x/8s/LszBwS0atE9AEiOkdETxPRrzvnXr5+0/Pw8LheSF3Dex8gohPOudeJiJj5K0T0cSLq+LDnMxnXX8iv2YdfOet9/3AQJu0gDDv2MXPH42NfaI6Br20fB/I+PEbg9DgiHNexi1adJpy40yuihsVxLD1RpPoieB1FLWm3WmacvI7NMfCz2cmEYxfrcTAtXBsiIsYTZbX6epxaIH2eAa5jxyPocYFZ8IDFeFXXzHyWmof9ADVwY33O3n+wWLG5wXG9Y+iyP8T42j4jV46xVK5StV5fc5bX8rBvJaKz8PocEb1lvTf0F/L0qw+9dc2+yMlFaUXO9MnDlM4VknZhYFiNyxcHknaQzqg+vE1TmazMqb+oxg2NjiTtgYE+1ZfN5+T4gcy3LxpR49RNldKeEofyOiLzoDp4OKOmzN3pcfVqJWlXy4uqb2lxLmkvz0t7fm5ajVucnU3alfKyngc8/KmWnEu1Udfj4EsnldXrHaTgCzCQ62m/QDOptLww55mBL5oMeJxZ8yBlWY5ZCPU8CnCts/BZxUDfY2EIXywp8yUPfVGgv/Dw29zB0+TMda+15Ho2Yv3ZdbjWtZasQa3RVOMaTelrxWv/APzZdx+nTrgWn32tb49VP1bM/DAzH2LmQ9VG4xo+zsPD41pwLb/s54hoO7zeRkQX7CDn3CNE9AgR0fjQgLtipzjzPcPKRLEmEK3dF3c2c1rmWxF/aZR5uJ65FVuzdW3/IrbmJ3fuc3hM7myeYzuK9S9eDBZBy5jW+KvchPfZc0GkUvo2wF/fNFgizpjq+MseZtKqL0zLMR3DOPPLng7x57DzL3sI7cCcC7oMdr0jWB9cjyCrzxldwjBt3DJYAzN9cmAhqF/z0PyOZuTzQnPNwlisjzCSvrRxvZotOJdV1m/cnl/nR/paftmfJqJ9zLyLmTNE9Eki+vo1HM/Dw+MG4mf+ZXfOtZj5d4jo20QUEtGfOueOXLeZeXh4XFdcixlPzrm/I6K/u05z8fDwuIG4pof9p4VznPjcbPb3HPrRxjdWG6fgp3NsaBzoc8ZBQb80l5Md22w2q8Ypn9LSSR0oO6R3iDTtwoGZCPivdgsgAn8TffHY7tqDX95qmR1b2ARtNmFH3/i5uB5hoOlQdW4R7IgbHxIpJLuDjXsk6LNbpIAutW5uCG9LYdtQhSH4r4HrzI0p6srul4Sd9xUC2OBn04c78Ay+vjMnw4HsaYTm3k/D/ZOFaTXMNcM9B8tYXRkapiwNLPDhsh4ePQL/sHt49Ai6asYzEQXt75eADfWBprCztIL0pYBaQBPQvk7nC6ovX8RgnH5p9+mgmnROzHpLSeHrdFrMMo7NMqL5b8xFJplj7LRZTC0Yi1/D2mqlZkuCW9BUJyJqgakdx9K2pikGCKUNXZPLAo3WlDlFxqxEt2MVhanoR4zqMycDrpf6XNJmPJrqZFyXACiplPUY8L6C+6MWVdWwVAjX09B3Idjxgb3UQDFSCgJs0iaSD8xre9+GHe7ptDH3W0gtR2vTzt6M9/Dw8A+7h0evwD/sHh49gu767BxQLrXiOweGkorBt0qbWTmYZpgVX7OQ05RRLid9xYEB3VcoQJ/47Bl4DxERY1hjWs8R54wJLXFgaRaVDqb6HISEusiE4yr/Hig6Q1214BjW74ecELWvEOb1WgXgs+cymn7Mwxq7lvGx1TwgpNeG7WIfJHo0TH4EhjWvykAElzWAtbEZa7ip4SLbB340HK8a66SeDIYk20Qb9LGtT5yR6xsA9RbYcRiea+lYSNAJsW18+zT8Nker9rXalLb32T08PPzD7uHRI+iqGR8EAWWzK+a0Ndk0p2GjzoC2ANO9r79fDcsWhUYrFHUuehrMVjRTw4zOfyYwxXjVFNcWx4hNbjT2MRlTHV7HhpZTGVTKdLfRbxBxZegqV5Bzy2IUW6TpKqS1MuYYaNbHYMZb1wtN9ZaJrmthtFdLTPdarabGVQOgwFxnlwFhg+S0MIReK0yMDDGvngztCeZ+aK5nGtY7yJgPBzOeMrDeGX3zYHRdYKjOGPxWTsn9GBqez8H7AhuFlxy78++3/2X38OgR+Ifdw6NH0OXd+JBy2RXz2kanMUYwmd1QBvMlizvufXrHPQtRcpms3mVHc10lgVjhBtyBNzubKdzdBjckMuYWK/Ncf5+G8JrtznETzEWMtDNRZ3kQO0ibnfocikZApJnVqkMmIGUYA9zFj+AY9pqhOW3N+Aa8jmI5RpC2ayUHadR1VBu6GkHc2VTHc7EJPzGt/b4mabcmBp8tNG5TGqSorMwY7sA7NPHNvROnkL0x9ze8RlfOPp0osMHWXL/iYq0SPYQhHXs8PDx+oeAfdg+PHoF/2D08egRd9tmZwvQKdbbaVwZawXBeSPlkwRfPmeg3TanZPQEQDYSvuHRos5Mwgk5TUuhvhsp/MjTLOvrkSL2Fxr8MGCLjAmhH+lzSLD57MzQiBnDe6MtGTaMbj9lyRrhT+Ya4VmY9FMVoBR9gHWNQeFilhY4ReoZ6w60PbnWmIpWfboU10Z+HPzesiCfKZ5trhqvPli6F1yFSk+ZnFMdZ4YwIZsawBpghSUQUwv1hRVGS67SOrr3/Zffw6BH4h93Do0fQXTM+CCmTa0e9GcoIzZKUMRfRXC9AQksupwUq0mBmt4w5lwGTE6kmGxWmTFNDY6CwAM4xldHuRB0opEZTJ36kgWbJF3QCSqYo0YHl0kLSXpgvqXEBUEiDg5p+RLO4WpbKMWSSXZRWXU3TUIhsXs7T0mtYUspGxqFp3dcv18lq/qGZ3denrydqCrbqMl9bwaYC51wnneCCiUeK5iObMCL3QdkKgtTkmJHRlM/DumbgvnLGno7gPNkkuOBr1K6zJbVQLCQw7pAV3FgL/pfdw6NH4B92D48egX/YPTx6BF322QMKCyuZaav8YXhtKZ50bm3/ODShlyGE3Do2NE4HX9ywIOvWgWOkBEEE00Xal0XffsD41JgFV1qaV32lhvjYWaDQNg0PqXEZOO+oqX3Uxbkl6QM6KW2q2maBvgsCu44y/3pV9gteP3VSjavX5bO3bdum+gZhzpj1ZktHD45IJd5qSfviKvMv7Lynk8qD32xCaZvg6+N6lGt6XM2Jn54zRQdQPDIdGX8bREKjJtJ3RpwFfXGTtheqYoZQMbZlsyJl7aw+fhCvHL9TPUKiDfyyM/OfMvM0Mx+Gv40w83eZ+Xj7/+H1juHh4XHzsREz/ktE9CHzt88R0aPOuX1E9Gj7tYeHxxsYVzXjnXPfZ+ad5s8fJ6J3t9tfJqLHieizVztWEKYoP7BiBFjKCyPZ0iajJw0mbRZM2JTViAPzM2WoD8zYws+288DXaRsVBn3hOsdA3fjQ9DVqYqq7WJu0I8ODSTtqiIn82oljaly9KtReraIzxcrlctJOhWK6FwpaH79SEapscWlJ9aFZPzkxkrRn5ufUuFJJTHyrfbYEx5ybm5H5VvV8iyg4ktWuBq4dunaZvKY6kZqtFTUFWIY5Viqw9g1N89UgwtCWwQ5zkCHYMNFvFXlfGui8bN6Y+yl0DzsLmiCtGtuyWeBGRiZy8orL6eJrMOM7YMI5N0VE1P5//Gc8joeHR5dww3fjmflhZj7EzIdKJhjCw8Oje/hZd+MvMfOkc26KmSeJaLrTQOfcI0T0CBHRzh17XH6obcaHnaPTssaMT4HJkgo6J5lgkkJ6lTgGmN0YQbeKFQBT3UobY8VR6MsYHTs0b60MdB7GxnV9ntVlMX1nL19M2iePv6rGoYm8SvsNXmeAuQhCPcf5ucWkXa7pHf2+PtHvKy2D6W7WCtfgzJkzqg+ZDBTRsPOdm5PjLy8vqr4i6A2Ojog7MT6+SY0bGZL94YG8Zi6yBTlGEdiDOKtZEvzspol6bEAiUrmuWZ4GVBLOUefkKGrBfWWERGKUo0ZmZxUbBPLiHdzPa9qN74CvE9Gn2u1PEdHXfsbjeHh4dAkbod7+nIh+TES3MfM5Zv40Ef0+EX2AmY8T0Qfarz08PN7A2Mhu/K936HrfdZ6Lh4fHDUR3dePDkDKDKz6Vcdk19bbKjwbBB8xisjrjMUaMWdF3OGbYOUpO0WtmeRRlB9SejZbCzLZ+k5mHmuQnXzms+p5/7lDSrlbE788XdMRYsyH0kvXR6hAxNj8vfujiUlmNm1sQvz9vNPZRyHNhQbLvkCYjIioBzTc9rbdtMkCV5TPSxqg7IqImZN9Vq3qOyyA0urwsm7uLywtq3MSYkEFjY2Oqb3BQ6MyBIWlninpN5xYlmnFpSR8fBTMjW7ILy1YDLZfSp0kRCFymW/oYKTgmUozOClOuk5GZCE7eAOrNw8Pj5wz+Yffw6BF0X7yibTIGJgMFcg1Um0ib7hSJ2bcqwAheW11th5FJYOqwEblA3TZHJpkmBi01MMejuqZqJkaEGqqUtEl46Nmnk/azzzyl+qbOC33VbEmkWSrV+VxQzIOIqAG0zmWg185PXVLjLk3PJu1cQZvx5arYoLfu3JK0F6YuqHHnzpyV+RrBh+2YGAPXwlJvSN/dcsstqk8LbMicZmdn1TikOheXdTTg1q1bk/amTXJd+oduVePSOXFdCkVN35XgGtYhWYmIiFjOh8G1q9dMdV3Ge24doQmg8mxg5nqQCLq44xj/y+7h0SPwD7uHR4/AP+weHj2CrotXXCm5bH32EMX0VvnK6MeAcJ+tlQYJ/c7QciiAiFlNVrivhZrpxr9kyAbD98WGBsGw1yd//GPV961vfiNpl0va90xDZtTMjITLzs3rcUgvDQ1rKQEMo8SwWqSuiIgWYI6tBR2mugxClYOQvbW4qMedOnM6aWdSmsoaA/+YQSgjMqGiOaDzqiYjDsOQMwNSnrvR0J+FdN7MnM7MQ+HRRViD2/bfpsYVC+Kn5/N6DyOXlX2RUtnSckKDtiJp12vat09n1qZ+iZTbTwT3vvW+8R7uFBZ7I7LePDw8fs7gH3YPjx5B18s/pdrRVGyMFGXGW104iDhSpaGs9jyY9bHVOAfzMXJIr5nPwjJALW1yRqG8RjMqNJrsL774YtL+3qOPqr6LF4S+GujX7zt3Wqi302deT9qbNo2ocajRbs3zMvRNAb02O69N8EZD1seuAZrrlbocz4p0IDU2fVmbzxh5h2WdqoaSwjjH0WFtPm/fvj1p7969O2ljVByRpv1QoIJIr08VzmXLNh2tl8PsuLymM2N0K83N2WyJS1GtSF/ZpHNnUC/fep/gfmJVKkv9qnvYluBu34/xDch68/Dw+DmDf9g9PHoEXTbjA8qEKybSqt14jDAy5gsFstvqQDq5ZXbjUcvLWOBUKMpu7vKMJG1Uq9rsw4ir0CQ9NGAHe2hIdm9rF4+qcX/7548k7f7xSdW3DOd5sawj72bSYsbOTuxM2pciHZ3WD0IIo6aMUQlKOY1CRNqbHtiixg31yS7+6JieI0pyP/n97yftfbtvV+MODsnx540Zf/6UuCSX5iR6L5/W+nGVppjTzYrepT5/9ETSPgGJNu982/1qXAFCLl8/8aLqe887HkzaLdjtP3T4cTVuYmIiab///R9QfQ2InExltUu1uChrNTsjkXwjw7vVuAZEALbq2pVxLZl/BnQVbcVYjuUYGeMGB+2kmWBVWSsY07HHw8PjFwr+Yffw6BH4h93Do0fQVZ+dyCW++urSSmpY5yMAtbAqigiih2w0VuwgWw4+DDXHibTu+lJZl0rGDC0UGRgOdETXrs3i979wTItFNhflmMtmjk2YfwY2HTaNa6XuPOir37Zjp+pL75Dv79/6Zw8n7YmxzWpcNiORayOjWsDx8OGXk/ZTP3giaVta6/O/938k7aG+ftU3fV789KNHZU/j6ad1pt+Pnn4yaZ8685rqC0C8YuqS0IhPPHVIjbt9j+wdFAdGVd+TT7+QtLMgaJKf1PPFbLzHHntM9R285z55Xz6v+jDjbu9tkkl3+nVdKitGutdkpuH9GEPpqZQRr8C9FJsRdyUzktdJlfO/7B4ePQL/sHt49Ai6bMZzYrKEllYAk5xN+Z2og+ke20R9eJ3N6ui0el3Mc17nGHOLEvlljzEO5jSa/y899bgatwA00fTZ8/r4sxKdFua1KTkIOukPvfktSfvAwXvUuN07d8n8G5q+u+O2/Ul7qE8izYK6vtRp0EIfH9Cm6dQxScI5f2FKPnfXHjXu7rtlXvMzuiLtLQ/K2P13ybhRcHGIiN73kV9O2l/7b3+r+jCK8OgrYo5PX9bRb9XK8aR93113qL6FktClBUjqOXNM06UYoff449qMv3z5ssz3vZqWw2i+pSXQDezTen01SC6Kzb2vypZBGS0se0akTXcraHLFrQwCT715ePQ8/MPu4dEj8A+7h0ePoLvhsuSI3QrF4UxJZRSbYBMeGkdYK0x8VGfGRUCfWAYCM7QweysyPjsKIRSNnnoTyvoefUXKKH/38e+pca+cEArpzCUt9LhpUjK5Ujl9/I//yj9M2gcOvilpHzx4nxqH4otLCzq76vTJU0l7x/3ihwaBrvUWsFz6D7/3H6u+yc0SWjsAlNoPf/gjNe7Jp4RGe8fb3qr6zp4VP7cAYhDv/eCH1LiXj72StH/jf/5N1ffYY7KuE1tl3V5/TdOZr770bNJ+9qUTqm9yQoQ+Fi6LT12qz6hx+YLsz1QrWvT9e9/TmYuI97xbaqVUarKXgPXyLOw+Ed6rWdgLsrUPsLaCrS+YaWeThmHnR3oj5Z+2M/NjzHyUmY8w82fafx9h5u8y8/H2/8NXO5aHh8fNw0bM+BYR/XPn3O1E9FYi+m1mvoOIPkdEjzrn9hHRo+3XHh4eb1BspNbbFBFNtdvLzHyUiLYS0ceJ6N3tYV8moseJ6LNXORZFiRluTBl4Hbe0ea4y3bDd0OZWBCZ+3WSzVWsSrYZa67YsczYrZlRoyj6fPHUqaX/nO99J2kfOabPy4rxQb+khTcG86f0PJe3Sck31feZf/YukvbggJue4Ea+AADo6c0pH+TUgmu/Qy+Jq/MmffkmNu/POu5L28fNnVd9sRdYqB2swX9MRf3/whS8k7f1f1MffuUvM57k5cX9MNSwanxAqbmxC03LgNdH+22W+rx57WY0jJ9fw1cM66y2dlXtkbk5cnrFhfW2PHBFqb8+effoYoB/3zW/+nepDChZpuelp7SagOIY14/EeRLoXozRXxq1nxq+8vm4RdMy8k4juJaKniGii/UVw5QthvPM7PTw8bjY2/LAzcx8R/RUR/a5zbulq4+F9DzPzIWY+tLg4d/U3eHh43BBs6GFn5jStPOh/5pz76/afLzHzZLt/koim13qvc+4R59z9zrn7BwdH1hri4eHRBVzVZ+eV+NYvEtFR59y/g66vE9GniOj32/9/7WrHci6iZhK2ajJ/IILQxYZ6A988Ap8dSxev9AEtt47wHvpMNvsO/fRsVoeRMtAaKJLzek37zc1QOn/lE7+s+oa2iF96/27tGxKUEe4HRZTFupbdaZZk/lv2aYonNbA3aX//kFBj/9Nv/RM17s4770zaD7zvQdX3O7/zO0n7oTcJffe//db/osb95V//TdJ+4vuafvy1T/5K0s5A2OfsrN5nuXWvUHsXzc/FWx+QeZ18TUJnQ0Pbjg5Lptt/rn1J9V24cE7mkZd6bvML59Q4vF/Onj2t+iYn5Zo1Ih2e/N+/JT78297xjqSdK+rNiVoVqF9za6psStCoX+2zQ1it6Qvar5k7/35vhGd/OxH9YyJ6iZmfb//tX9HKQ/5VZv40EZ0hol/bwLE8PDxuEjayG/9DIvNVKnhfh797eHi8wdDVCDoXx9Sor1BiNrNNITaa72CeR00x3a0ZH4PgQzqjKbWgKeYNmvFBqM0hNOeaLT3HsU0iSviuh96TtJ+LdCljAupw/4EDqqs0K3ub73zn21XfpYtCgU2MyGdlDZ3SPyhzNvLkFLUkiuuffvo3kvYrr2i6Kh0KjdY00WT9RVn/3/3NTyXtuw4cVOPe+YBE+fUbAYwLpyVzrn9IXJKxQZ1JePakuEADJmIxAPHFUYhIGxvQJZWzUJbrwF16vU+fFpO8v19chvklbUsPDMi8lpYNndkQIYpbbtml+k6flaxA/Kx9+3R5qUYTXTH925lOAd0GmY/ZjHYjMfIzZWjhdLpNvbHPevPw6Hn4h93Do0fQXTPeOYobK+bjKk1sfBmb0jaQ8IJRcrFNhIH31Us62gvL5WD0kdWgq1Rlt1iVMCJtYm3ZviNpf/Q9H1bjsiAgMHVU7+zesVP00nYUtNk6NCxxSUug4TYwok3kpUtidrMxCfOQDDR7QczPPcP6PKuLsht98cgTqu9XH7o7ad++Xea0eE4nmdx2q2iuUVZHCiqzFXTdlxa137FnC1Rn1ZeMFhbEJdk7KW5NwZT9OvScaNLdDTpwREQ/+iGuMbAYk9oVmJqSaz02rstLTU+L4Ii9J0ZHJSUkBYkrDRMFqkpnmR3zFJQPSwMDlM7qaxZCdGRo3M8rO/deg87Dw8M/7B4evQL/sHt49Ai6TL1FVK+t+Gw2wo1BM90Z6i2G1yhQ0aqbrDfwy2154YwRj7yCujmG0vA2vlUD0rBw3APb71LjXnrm6aR91+g21febv/QPkvbAgnZSL770w6T9wiERZEiZktBzIFgxDWKIK2PFl8tkZY7Nuk5nyISy99G6dEb1vfaUiFT8+0simDk2qevFjW+X/YesCYV2EAnWNyx7Dtu26xpoeZK9D9LBaTSxWY7Zgjpqe8a1dMLlUfGxTx3X1zMfYLlluX4H7rpbjZue+oF8VkP728ODsh+xvKR99oFBid7L5WQvqGpqDgShXMMwZaLfgEZTEXCsx6XS4M+n9T3BV4Qq14mg87/sHh49Av+we3j0CLpe/slFbTMr1mZ8jNrwhnpTyf6QJMPBOtrzbCN8YSxEGXGglwDNKJuwEODYUMaFJWM6VuSN/+w3/6Hqq5yTaLu/P/Sk6quXhOLpA5pvbmpKjZscFxqqODKg+nQAlUQYtkwZ7ByLzTzcr9cqtVPM56efFpN+alSXVhrfISb4MFCRRET5IRGvaIE5+swTf6/GtaqyVnt3al364T6hx7ZvEQ26W3brKLb775DXpSW9Vo0lieR784Oik7dlUssvbNsi852Z0RGF1YbMEXXgiIju2C+RckP9ci0yOU1FVmtru4CrXsMFtK4oob6c0YfnDfxu+192D48egX/YPTx6BP5h9/DoEXQ96y1qZ6pZ6k375Zp6U2PR1zfHCMHftsk/mPiPvpD1i5SevdO+VQR+fxBLnxVT+OWPfERemLDJ737r60m7wPo8iyk5joPP2r5D+5cMipP9m7RvGAPV1AK6zdX0PFIN+ezBlKZxBlMi1rBls4SfVlva76/AmoaBPn4/RHoOjMoeQM5o5YexHOPYi8dUXwmEJC8eO5y0jz6n9yn23in17XaM6/p59+wXenDukoQP79yhxS3HQQBjZnpW9QVwLcY3jam+++8VTX+khZcXF9W4bEHmbEVOO96bbGq9KX/e7DW195BW71XB+zv2eHh4/ELBP+weHj2CLme9xaBBp4FmvDO62p305KwJjmZPKqV1tTHZX5lRxuzBj0azfWVeGF0nfWUTnfbeu9+WtL/0J/9B9VUXhBp6ywEtcDAKGvOlkkRgje3WkWszS7KGmX6doYXlsaKymN2pmhb6oGWZM7f0eQ6OyDzuvO3NMnezHsuwWEvGeqyAyelSICpiXJc8iIy8+cDtqq+1LNr/Rw6LGX9+Wuvcn3z9paR96306mvGdD4qYxRf/81eT9n1veqca118UM7vfituXZb23bTHm/5iY9RgFavXj0lBiOTBmfBq15YBSs+a+ut8DveBy73sz3sOj5+Efdg+PHkHXzXgUn9B9EEHXWieCDsBGhyvGALd1TCBsOyMCkMKEnMhUmsXdfjhG35g2+77+7b9N2i8ee071/dK7HkjaR07pUkUOZIovz84n7cXvfVONG5mUHeZMQe9M47kVYGd+y4Beq8m8nNvIsBbHGMrKMeZAS64Z6t+GEnzWkhEjKYF75MClKuS0O8FpcRlSdX2MBrgrw3m5TpuGtTbb8bOyy/7CIV1ptgyRgrfukR33v3/0MTUO77Eh4xpt3SrJTO948B2qb2hAknJykLAUGuGJAKLf2FRaxXsV2+tF2pnlXlc6PZnDVUd4eHj8QsA/7B4ePQL/sHt49Ai66rMziV68FZxExqDFxmfvoDEfx4Z6A78lMDQR+rLoFznj27Py5+0JYASTtHdNTqphf/Bv/2PS3r9dR1yN9MuSTzW1eMW5M1Li6MgJaZ+9pP3cmfKPk3bDLA1oHtLmftlL2L9Zi0vce4v46fu3aB91rE98z81DUqLq/IXzatwzxyXi7Ygp+zxVEX+7BeuWDjUlmnPyelNeR7+NQObYxIjM35l0xOK4ZMe1Ak3tvQhilP1AbRaKe9W4LVuE3rQipKNjsFZ3aHqwAkIXAd7Ekb4wmazsOdh7LoR7KVCssNkzwn0t66Nfeb2O737VX3ZmzjHzT5j5BWY+wsz/pv33Xcz8FDMfZ+a/YObM1Y7l4eFx87ARM75ORO91zt1DRAeJ6EPM/FYi+gIR/aFzbh8RzRPRp2/cND08PK4VG6n15ojoSjhXuv3PEdF7iehKfaEvE9G/JqI/XvdgTBS2k/+DwNrIMMxaIiBYEQTbMuIAACAASURBVEH5VGcrwQJtZsvjBB0ojVUfBRRMFBszCgQgGLTLS2d0RdAAtMX33rtf9aFa+bvu1eWUXoIlqS+LiT8+rM/l3Iz0Tc9rVyBFYmCNgE3vFrRrVEtLdFo91sefJ0niuJiT45+duaTGnb4oQhwzC1pzbQms6VoEuoENbWYHNZnHWdL6bndOiFnfqsjx603t1hwYl2SUzRNaYKMIlN3rQCP+3uf+HzVu714x6w8f1aWyCgVxh0rViuorV+T1ICTTWM13df9Z1xGpt3Ui4FCcxdLR7Fau73oE3Ebrs4ftCq7TRPRdInqNiBacc1eu3Dki2trp/R4eHjcfG3rYnXORc+4gEW0jogeI6Pa1hq31XmZ+mJkPMfOhUmntuHgPD48bj5+KenPOLRDR40T0ViIaYk6i77cR0YUO73nEOXe/c+7+vr7iWkM8PDy6gKv67Mw8RkRN59wCM+eJ6P20sjn3GBF9goi+QkSfIqKvXfVYJD57GKwTCmi+g6II6DAXrfmeFYgfY3127uCzW9+nDqG6dcNrRRhKC8IWx01I7PYBobK2DWhaayeEpk6dfVX1Tb0qtdQql+aS9ukLWgihEYgvW1nQ/utATnYFcn0QVmpqO8egGx+F2u8vVWXs7IBYY2WTOYfrmM3qa5YNZe1wDyY0CWUFJz51v9FJ33+b7HcU4XqObdF0Zj/QigukfeqD90rW2wtffTxpP/If/5Ma97GPfzRpnzuvKca3vO3BpG015fuglHQeahOUTT2CIujor6rHtmqTqv1nWif701Bs7go9vQ71thGefZKIvswrhZ8DIvqqc+4bzPwyEX2Fmf9vInqOiL64gWN5eHjcJGxkN/5FIrp3jb+/Tiv+u4eHx88BuhtBF6Qok18xY6357CDiKAx0Xz4nr2MwsyNjUiGtE5d1dl22ADQUy/tCs6+Yh2i92ES4ZSDrawhK9e6b0Obn7E+E4tk6rGONZitikj974aLqe7kic77k5LMe+OD71bjnn3o+aTdK2jzf3CfnNjEi7dlpXSbq5bK8Ltyhyxzfedc90ndBXIbDP/qhGvfKjBx/saD3YxZDuU4zIELhNPNG9+2U981d0tTbj34sZbQ+/A4pGzVqqKtCTdatL6P7Ng2LmT21V8zsyqEfq3Gzy/L6TW97SPU9+19E3//NH/mk6ksPbk7ai3W5ZhWntfaaJK/ZCCRmIJsSH8gw1m5TAPWxQuPyJBGivHa06cr7PTw8egL+Yffw6BF0t/wTc7Irvqq0DZruodlpNGIWV4BVW1cOIcesNbUZn4rEnI7BdK839LgW7Iza40cgC704LybnS0eOqnF33yM7wOPjm1XfxSWRKZ4Y0xLRD8Gu7+ycmPv1ml6PLeOyG71rXOvTRdUqtMXEn5jQn7V5s7AEe/fuU31794pZX8nKZ4++qoUyCsviCriUvp79/WK2jhRlJzptru2tO6Ws07a79Vb9meelku25yxC9Z4Iv74Ed9x1QkoqIaAEYhIF+YUL6BvWO+637ZQ223bJT9ZWLRr8Pj78k16mZh0i4gmZhokjunZTVPUT1clhG5/Sa4m48m/JpCbm1Tgid/2X38OgR+Ifdw6NH4B92D48eQZfFKzgpU7Mq0gcj6GytZKz+FK3tvxMRtYA2q1ZNNhhEYK3ns3MKhARMgB6WhkKqcGFZx/wfeLNorWeNEIJbkPdt26wjwXbsEGHDJch6O3b0uBoXVMSHHC4Mqb7ZS9NJu7Qg+xSbJ7R4xeiYUF5DQ7oPBShH0nLOt962XY1zOVnHGpuoRxBfLDXQ59XU0F4oP50N9LV927uFAtsG2Ww24CyEyLX5so5cy4AgxkNvFwpzqqVFPItDQqVeuDyn+kYmpJR0Jq/3FWaA9sOoxP4hTbk2kTJmTRmjeIWLQJjSRpnigxBYiq1zFmnylquO8PDw+IWAf9g9PHoE3dWNJ0eteG0zXBksNsgf7LYY+uyx8HVskliwnBLa5zZhJgXmaMto3xXANN20SUxd3n+nGleBSL6ZGW0SFkDUIJ0zJYIg+ivVknnt2qwFGbb2CwUW1/UctwxJXwbosGKfdidaLTGtB/u1aZrPC23WJHFRdu7WbsfoJvmsqKV/N6o1WYPZBdHArzQ0jTXZL2Z2cUDPcftOoRU3jcsaNOva9QJWi5pVHaLXhPXZNCRagVvfrss/vX5eaMQXXn5F9d23VajIXJ+OjEuDaV3G6Etnax/IPRfYKsVYnwD0F235MSxvtkq8IimrdQ0adB4eHr8Y8A+7h0ePwD/sHh49gq777M0OGvDos1vKCwE6FhTbgesISVZqQmVhqG6f8cFwv6BZ1f5lLg1ijoNCeQ3cqlW6nnzqiaS9s6XDWffuEXqtXtUijVDZmFrLEoY5lte0SgO+o+fqWtiib1AotXxexCusUCKKKE6YkFtyclu4jPiXQ5u0b98HlBeWhyYiIgiz3QGftVzT88iCetHI1gnV1zciIaeVhlBqdUO/ZlJynrk+rT1fq0pYc6sp997mLZpGHEvJfTCkp0iFQaEma8ZXRtqPMVzbCn1ACefY7G84uG8j9PVNdl8TQmRDmzXaFg1dr+ab/2X38OgR+Ifdw6NH0FUzPnZEDbc29Yalc2wAXYDUG5juQcqU0QE9M5sp58D0a7XENK0brTDUGKuUdWQczrG0uCR/N4IMl+akb3BEm5XNphy/vDCr+tL9QD1VQJTClBKKgV5KRyYCEFyU+Tk5xpJR9t1zm9BJYxNaBbwGpnbfkJjIAwP6XBZLMv+leX0ufSzvmxwRym64oCPLqhA11wCKjoio1S9jsRSXM9rqS0uy3mnS67GwJK5SsyaftTijs9423yLiGA+M71J9NCDzfw2uLRFRAH3ZnLgrsaWP4Z5zoZ4/UmwYiBi3rE4jLILJGg2ClUe5U3lzIv/L7uHRM/APu4dHj6Dru/G1VnPNPjTdQ2OihGiZoJljBBMc7IY2zeeEGTHxmzUx3dEEJCLKpMAVMKZYGcz6kydPJu2RptaB6x8TwYrlinYTFhbk82oL+rO5DBpsEbyvZSqChrIDnB3UO+Q1OO1aQ+aPEX9ERMWimOSlZb1zXK3KZy9HsNsf6Ii/XEF2sBuRLg211JC1Gh2W3eyMubYtcEOsPl3lomj0LYAeIO6Or0DWIwQGgojo8py4F6+fkGs2vklH66XH5MPHd21TfbMNmXO9pd2hLDxCKHbCpryZciOtm4rlzWg9gKS60bG7QmFFHSJU9bs9PDx+oeEfdg+PHoF/2D08egRdpt4c1dopSlYwD0sJBZGmHDATDX17Z6LxkLaoR9oB7AfRgQYIVmDJXSKiGMQm+owWOtJ0F89LaTse1P7fxC1C3Zw/8ZLqW0KhCxNlNQU+6lBRaKe8Kf9brYj/msrpCMClsvh/DLWWhka0nzsDAg1HjuoyVOmU+MAuI3TY9q1azHF4SEQs0wOaNqvMy35EBa5LzmQZ5kEItFrVex+pSPzSbF3OGfdmiIguLwq9luo357kgewmzVZnjbdvfocZdLMm15bLZwwAaMdOnhSRdKOezXJFrm9NbB5opMz57C0qJMdzTkRmHr535nb7y/LjrQb21yzY/x8zfaL/excxPMfNxZv4LZs5c7RgeHh43Dz+NGf8ZIkLN5C8Q0R865/YR0TwRffp6TszDw+P6YkNmPDNvI6KPENG/JaL/nVdshvcS0W+0h3yZiP41Ef3xesdx5BJBCJvrwqqt7ReMRlIVQa30PNAduX5tgjchCo3TctqFQR0VFtdBG37ZUGPgaiCVt2DEFEo1MecGNmm99lxBPu+8qeIaQOJNEa5M0eieOZI5njx9SvXddtebknZ+QOi2b337MTXu73/wo6Sdzei1OnBAdNjPXJA5HntlSo3bs08oxo/9yj9QfZNbxOS/dFnck6BkEnJiWbvGohb6QI2+C6fOJO2KuXu27JdEpDPL+hgXZ2XO8w1xE87M6gSiQr+IY5yf0+5EFqIIs/1aO78OoX15oCJtzQE0r2PDMWIEHTJ2sdPn2QAKNjLa80GbMraRe2pMxx6NPyKif0miFjhKRAvOJbM+R0Rb13qjh4fHGwNXfdiZ+aNENO2cewb/vMbQNb9SmPlhZj7EzIfKJj7bw8Oje9iIGf92IvoYM3+YiHJENEArv/RDzJxq/7pvI6ILa73ZOfcIET1CRLR1x/Z1itN4eHjcSGykPvvniejzRETM/G4i+hfOuX/EzH9JRJ8goq8Q0aeI6Gsb+UAr4igfJE2b9RaBIaFELqz0PLxOWc1t+FjMOnLW8U+L02R1uxUFCFxKwyxjLiNU2eKsLkNcBz9sdJOuA1eaFvpnfELEEa2O/gxoyveP6jDYwpCIariUECTjW7SXddfd98oc5/XexBJkipUX5bMHBozQR1ZoqNmqEefcLJ89B1rx9UVN0W0tyFqFJrvvmR/JvkIanNnxWzQFOHNeMtjCIe1T77lNNN9f+f73k/bhE+fUuDsOyP7A5Lheq3Sf0Hklm4kG7ncI59lq6X2cGEUmYx3KzSR9IewBWKGXJhwisiHl7Zvf3SDByc/SymbdCVrx4b94Dcfy8PC4wfipgmqcc48T0ePt9utE9MD1n5KHh8eNQHez3pyj1jrlm3AcopMk3SqRC3idCfWpoQCGqoRrM+egjE5gNMBCeI1tq4kWgkb7wrQRWoDSTdsNLdcsi4mbh8yusxe0yfnk8xKVF2Q1bTZVEdMvhAi6mcuaalqCKLyz57SQA4M5XQHzfNNW7XZkilAyyWTwVc7Kep85LuWrKtP6XHi7ZJjdvVmvx9RrJ5J2H0QUDpust2kon724rMt+tYBabQJdteNWrfW/bc/+pD04Nqn6SmCR1yr6+BTKvNLgAsZGG74BmYSRMfEdUHFNiB61uvFYIiAyUYTcFoWJO7nJ5GPjPTx6Bv5h9/DoEXQ3EYaI6sa82dgb195hXLUbD+1VpXNwtx81v0xJUAazPjCVSRlcgxDb5jszSkF5qYLOiDg/LWIKIxm9k54tink6VxZT79hJbWY/d0xM4Xkje5w5LBFvmYzsngeRFp5YuiwuQ7mi12AHSDiXoRpu7fxFNa55WZJMXjxxTPWFcNrL8+CemMtfnZJzyRy8V/WF/TL/KpjgZRNZNrxZds/PX76s+lpNuU4f+9gnk/au29+vxmUg6anhtPtWbUJiTKBTQDgEiWiMkluVkCKvndFhRAEPgjJRDXODN+FtTbMbf4Vuuh4RdB4eHj/n8A+7h0ePwD/sHh49gq767ORckg3kOvFptH4Jm/WA7ne9qZ3DFHj0KGCZMsQevg6svjf48ynQrE8b+qsMmu+Zfi128PphoZMykRZJ2DcpmVezZYlimylrquYUaDuWDJOZAZHJMIB56GEUQhBX0dwFY2MSTZYbkn2F186cUuMWqlAie1HnPeCM8bPZfNbzJ+Q67dqqRSu3jMp6YLniOSO2uAznfOKcznqbKAiN9uF3fjRpT1WNIAgodVYNlZrNCX2XLujProB4aRmuWWyOEayjXoE0Heq2tMy4Jvw2N80+lmtHe96oCDoPD4+fI/iH3cOjR9D1CLpGB934znE/WjQCzf+gY2wdUWw06FDnK4T3pQ29FsFrK6KRhsSYGEz8MJ9V45ZBQKFghCdqIEDw8vGTqm+4KHwVJvJkhjRFt/1WiVwb266TQm6/R+irAohSuKpej0xdzMzKjC7dFIKweQXOc++de9W4sTExs7M5Te29+qqIGs3OAGUXaa5wfm4maRe36Ai9ClQ+zRUh6Sat1/snL4lrdOKcTrTZcbesXRCLOd4yrmIL7kAbOZnKynWpG2G4ZlPOB93PYlFTrpWSuGxWvAKTZlrgi1p6rQ63e9P8Trt21KM34z08PPzD7uHRK/APu4dHj6DruvFXNNutj45+OVnhCfTZoY+t6B64K1bwL8ZjEPrlnecRma9CfI2lo2MTchtkIBPKrPD2XeL3Hn7icdV3BHz47VsmpCOj/X7OQxhprM8gBB35AfD1y0ZEo1mRLLjlZS2wuHBRQk4z22R/YOuE9qlv2yNljgdNjbVROPHXTsh6LFY0NbYZ6Ma5htFrB614ghLcNZPBd+ScUHbDo7eovn377kvamUDCkYv9eu8olYMy3qYYW60pdyvWHCAiIrhf0rDHELA+ftShZDgRqX2sJghZNIzP3gABj4b12WMfLuvh4dGGf9g9PHoEXafe6s12+SfubKqz0YVD0z1AE9wcw8Hr2FIQmPWGQhbrzde+DtamAJu2pHIOSiqnNI2zd9+tSfuFHzyu+o6feC1p54sS4VWLrc64rMGTh55Xfa+dF5N2YkTEIBanTMbajFBU6ao2TXNw/PIpObchUw7rUfCURgpaf3/buHx2vSqRZUt1LXLRvxWiBpdLqo9B+//clOi/n53SZnyzJmu1Z58WnijkxQ3BKtj1tF5TdO3svYMZbNmMdlfS4LItge79/JymAAnM+CjSJn6zKRNroo6doQCbIKTYMJRxHLSpN2/Ge3h4+Ifdw6NH0FUzPqKYFnjFZFkV+wbWBze0KcKQ+JDCEk+hjqRKg6BEJqUTHTD5BeV/YyNf3MLoOrMdH4A0cxp2yMt9Os2kBFVAwz49xzJ8vx781CdV308eezRp/9WhF5P2+x98lxo3N30kaWerWjq5OSXzn8PklFAn5NTBTZgLdRLLEIhXbCaJEKs09Vo1QJijasoivbwoO+nz87LbP5jXrsDuinzWrVu2qL6ZU6eSdvOYRNqNNTTTsmuv7MDfBVLaRESF8nTSHgqF4Xg6q89lbFTcjrOvvKb6+jPiouQD/cjMnJFyCcMQaZdlff+1wFQPTfZSswRmPVJKeWPGp+XeCU01XEru/c5Rpf6X3cOjR+Afdg+PHoF/2D08egTdpd5iR812WeJV0W+6sJPqSyFVBjOOyOi1Ax0ROStsuXY22yoKEI7ZYn38BpbpAZHAfEX77EUn/lqxpf2uLMxrx7adqm/z/yDiCt+L/i5pP/WTH6tx5Yb4w4VhXZKp2Ce+M2rD14yYR5CXhVyO9XkuVoQ2agJNZFc0AxFjGRMTuQzLuggCi82G3h/IL8tnLRzVYpFUgbF9so6DfVo3vn+7RArykL6lm3m51i1YqqGqoXcvy77CzsEx1YdMWXVJzx/3IFxT7olyVY+LwWevW6VUuBapnLTjnL6vUkDFVVcJW7TLP60jCrPR+uyniGiZiCIiajnn7mfmESL6CyLaSUSniOh/dM7NdzqGh4fHzcVPY8a/xzl30Dl3f/v154joUefcPiJ6tP3aw8PjDYprMeM/TkTvbre/TCs14D673htcHFOztGLOBCbIH81p20f4GqiywJTACdGyMdFHMZj4KTyeMalisIM40OYtOzHTIhi3uaJppzxQMINGaKEFum0pUxF0z3ahkGbvvkvaED1GRFSLxDxnq0HeknObrYtpWop0lFyYkjmWSSegMNA6vAzRXSY6K4A6WmnTV4Fkj6WKRMblQmPCpmRcoVVXXSN5qEI7KfTXhCkTVZwQGrSa0eWZFlmMzVJaaMTNNW2qz89JVF5fn6bvFkoy/8qCjvJDkYoWRDoGxgSvk8yrmTGiFKidSJ3dpgZQzUFaHz/Tvt9t5WHERn/ZHRF9h5mfYeaH23+bcM5NERG1/x/v+G4PD4+bjo3+sr/dOXeBmceJ6LvM/MpGP6D95fAwEVGur3iV0R4eHjcKG/pld85daP8/TUR/Qyulmi8x8yQRUfv/6Q7vfcQ5d79z7n5MEPHw8OgurvrLzsxFIgqcc8vt9geJ6P8ioq8T0aeI6Pfb/3/tqp/miLjZdlBYUzWMfrTpi8H9joAmajntaxL4TKmsoS3AD40h5Ha97DuXMplRILaOGXaGAaQGaJCHA5oaywI1VjcZYFXQbNyyTeqX3XHXfjWuAdTbpUuarqpWxUd1Djgj49tXy0AFGRpndFCorGhO3ldv6GytOootVrS/jTX9UKwhq5PGiEBscWhQi3SMFmRBRofEKhwa0tc2nZVjNCOdEVdvSSZa5ETAI2oMq3G4pXHxov7dwlLJlNU/WAsw/xrUhKsF+h6uoihFytK9cp4h3Pts9PFxjyRr6tHF7f2rcJ1w2Y2Y8RNE9DfthyBFRP/FOfctZn6aiL7KzJ8mojNE9GsbOJaHh8dNwlUfdufc60R0zxp/nyWi992ISXl4eFx/dDWCjokp1TZN1qPeLGIodRNjNJYZ13JiAuVCS99BFB60w0CbQ07XdtaHQMEAmG7J0EmoA56KNeW1eVgopGystdbTaTm3XB3EIFLaJLznLhHAON+vs6tKS0K3LS1LFFetpc34OlCHi2VNJ2VBzCJFYndXjFlZVdF1+voNAOWYLYjZPWoyBMfBVN9s9nSGYHkGwSUZaGr3LduSY6bMmhaasgbpspjxc+b+q/bJOj5zWGe9DYxJttzI5ITqO33ubNKuw7zQ1SIiaoKeXs6UFcvlxEXJw32bMrWykD625Rda7YzEcJ0CDD423sOjR+Afdg+PHoF/2D08egTdLdnMTEFbQWY15QU+tQm9dJApprpi46CAW9o02twxUBppaMfGL+rglhMRUQv8PAxLXDBhtUXwy6t92oecBQomTdqfz0DNuDxks+UK2s8NodTzbZt1HbioX943fV5EJp1JhypCSOjFmRnVNzsnvm0QiC/bzOi1gshcCk14aBZCXQuQ1dVvakf3s1B2A0ZYcwjCoYvQla9qmq8Amu+U0WuanpdzqZw+k7TjBz6uxk1Pi1Dns3OaziwANTlZ1PsK80CxTewAscuaFuCsXwZf3IQuNxpyPhHsl2RMvcIihDgPp3WAWiq7ssYZWxMb4H/ZPTx6BP5h9/DoEXRXvIKZotSKWbsO07Yq2stB5JCDPmfLLoHhbcv0hA7tczntwApgOIyu09NKR/I+l4LSuiY/KQv0UstEUi1jSaOmFjjIpmQu4wUxF3ds11roF54T8zwXa5M2H8oxMpBdFRrabBCO31fQkWvDdTlmDUQ8yRwjwrLVxozPwfELWTlG1rgu6Yasz4ARwNiE9B34V4ERJM025ZyDWN/SriSftzQl5vlZ4wr84OVXk/Yrs7ocVn1JIgXzJd23/8CdSXvfAQlHKc1fUuPyI2LW50x2XwB0aQxlulpl44qGYsYH1oxPrawVh96M9/DoefiH3cOjR9DdKq7EVGkn2afYRtCBaWaFtCCCjsEcD0wCRwC77C0bYgSIwLQ2ngA52DxnG+UHZZ4CMOP7Y/1Zbk7MspoxW4tjkoDR36+TMdJQ+dNBFF4xo6PkBopidrdKOvGDocbRYBHYA1OZtF6dlRct7U6MDYuJWAFTssWm+iiwIZGpWpqC806TmOOhiShkcGXY/PYEBOcN7IcV0WAWFyKXNWnUeUk8aqak74knDqth33z0R0m7YhJVKhm5KaolXUZr9zvfk7Rbm4UJObesFdr6ILGpkNUMTR/cx8GyuAzRfEWNq4GQSGlZRxHW2olI1XXcY//L7uHRI/APu4dHj8A/7B4ePYKuU2/1toiEYU/Ut05gvoNCyCoLIbONnKZqIqDlMsYvagDl1ayLv5PL6yUoBuDzGUHIZg0EJxviv44ZN7EK5ZAntuv6ZVFZ5uzMnkMZKJlBCDUbGd2sxs2kjybt/KAWx3CLMscW1GZrmH2FiIRGy47oPQEHmYCplPjUTUNntkCLntOmtl4eymfDxkjdZKwRyTn353U9ujK8LwMCi0GfFviMixIN2MjrfZAmXM/6ssz3299+XI1jKMXcMiW4XU7WeP99Ots7N7EjaZ8ELZLS4KgatxjJOs6kNN3bD5luxbxo4ufGdYZdGjL6zPYJpaKVteI/0PcDwv+ye3j0CPzD7uHRI+g69VZtR69ZhgDN85Thw7AvDeZnylB0DK8jQzVlIPoozIJGvXEFykti7jsTyVcsiknY1yf01+uvHFXjtu/ZnbSXF3TEVRl078fzOjIulxFz9MfPP5u0N6f1HNN9kvySMhRjswJ0DSSFhEYwAVfHmbWqAe23XJMkGVOxWZOKztCPYOLHYIJn0zoKLw2Kw+eXNI24a8eupJ0ZEp335UBH68VZWbcgp83n4xdFg+7QyyKKvMDvVOPmFyVyLb9VX5d73vJQ0r79PfervhQMnYH1mSftRmb6ZY4l1hF0c1hfCkRGWjVNvTkoVR1F5glqdy1HRhAR4H/ZPTx6BP5h9/DoEfiH3cOjR9Bl8QoRi7AZZQH424aVI4bwSCy3HJo6bSkI38RwUyIiTHpDN71lfPYmCjOaObZAwD6GEND8Pi0gcQ4y0SpLOmzylv13S9+ApomOnzmZtH/09LGkfd82ffzbh4SSiZa1X9eKQDe+CVlvZADnFhoRkAD8vsE+oKTMhWnEkGUY6d8NiHCmGN7oQu3LYk2+bbdsV11nLsm5NGYli2x03x36s0jW8aWXz6m+F87I+6aX5bzmR3SIMI2Lr7/p3rtV1+hBeT1v6pycPiXXerYhew5hv360Lhw7lbRTofarMxCei2Hk6SBlxsm1yGV1pmImvdIXrZNO6n/ZPTx6BP5h9/DoEXTVjE+FGRobXYkos5RXitCU0e/LgImPpYHt5EMw8dnod9WrQoHVIYKOTAZVOi2mUmyELWow5caSHOOk02WclqsycOutd6m+3fcdSNqHT+oMqp+cEpNzOQ/02px2SSZHpGBulnXUGZNEUDFmszW1jjnq/NmMuABexxBFuEobEEz32BkzHhyHFoiF1E22YxSIWX9yaUH19Q1L5CAXhLo6fFpTdC8+Ldrtp/RSUQMi2bKb9krH3TvUuOF77k3ak/ccVH2XinIu5y/o0lCzFbmvwgJo7TW1vT+5VT4vZ35is2jGw3MQmhJPmZREKWZMGaorL0+nr1G8gpmHmPm/MvMrzHyUmR9k5hFm/i4zH2//P3z1I3l4eNwsbNSM//dE9C3n3H5aKQV1lIg+R0SPOuf2EdGj7dceHh5vUGykiusAET1ERP+E7us8AQAACJVJREFUiMg51yCiBjN/nIje3R72ZSJ6nIg+u96xcpks7du6El0WmK3ukNE8N33QTkNXyooYqPeYJJOKlDhaKovZXanpXdnlmoyrlHRZpHJNTOEI5K1PD+nPevDD70/au+9+m+qbHxbz/MQFffxDJTH/d2yRyq0vHX1JjdtyWSKuJkp6d3skELO+kJXjZdjs2qNZH+rotwAq5Tac7DabClLURNM91GZlKiORcUFK+thoxNVhRz9O6XM5fEGu02vzF5L2NOnPqm6SZKNo6zZ9/H5JLKlAJN/Qr+oyheOTW+A9WgZ6EeSdeUz33dIPLhVMP6ppNzIN8tEFwyJlGU136IiNawTsipE9pEbbq3SdA+g29Mu+m4guE9H/y8zPMfOftEs3TzjnpoiI2v+Pr3cQDw+Pm4uNPOwpIrqPiP7YOXcvEZXppzDZmflhZj7EzIeqy4tXf4OHh8cNwUYe9nNEdM4591T79X+llYf/EjNPEhG1/59e683OuUecc/c75+7P9w+uNcTDw6ML2Eh99ovMfJaZb3POHaOVmuwvt/99ioh+v/3/1652rHSYoi2DK9lLq7Le4C/Wn0+hIB/49uGqo4BIgtHmzvXJF01fLBlUcyVN99QuC/3lzHdhrl9EE7IFoeh2fkJTNffsfVfSPm+00I9Oie9cH9P0TzxyS9I+NSf+ajavRQz+v1fOJ+29TR2htxtKUW0BqqavYARBWCKw6oambIHPzg1Zt6iuea0q6LVXjQ9Zj2SnpQGcZaWmKcA6ZHLNl3XfpYp8XrUg82hOaL+8lIUfkbT2+7P3SZba2z/wwaR9bre+d+qQjVhraio1VZD9h00FffwcPEFYBcwZCiyNQhxmPykHwqaplLwvNGGPuEVioxmvzJ7X+fneKM/+vxLRn/GKjOfrRPRPacUq+Cozf5qIzhDRr23wWB4eHjcBG3rYnXPPE9H9a3S9b42/eXh4vAHR1Qi6gALq4xXzl7kzbWaYCWW66+qvRisMuthWeE1BggHQREUTibQpL6ZvoaVFDPJQIXVwWEz6xlZNRJyYk4iuo+c0tTdbA5NwQid+bD0oggrnn3gyaYcTWqzh7Dmhoepl7a7M1KXE0ShLdFd/Vq9HJgeUl1nwFqxrvCC2ac1os5XqYrsvGhO/BHZ9pSHUnj1GE+glzudVX367rE99UCjLWl7TX3SrJMZsett7VNfg7VKe6SQmjyyeUeNiiFbL5rSoYCaQeyRa0P7KHNByGN3ZZzQQCwW5r+KmvmZV0AeM4ElomroFdVirUlPPo9pWFkHXysLHxnt49Aj8w+7h0SPwD7uHR4+guz47MxVSmauPW6VeEa85zvrsMdQD689pX7wMflINxCVS1mcflLDJVFFroecHxVfMg/jkS3Pn1bi5BTn+Hfs0LTcL7tpZE5lwz5uFQrr8+p6kXTnyrBpX3C6Clo2zOuT25MxrSfvE3OmkHZrMPAYRy5a5C9Dry2E4rrl2cSivG4YGbWKQc0588UxR+8M58L9dVq93Gd+3Q+i2nW9+UI3rP/CmpF0yGvsnQYgjLkl9u70F7fOGGZlvaHgttyRrFxmRjgz8XmbAx+aa2UuBgLJGU4cuo5Z+E/i2Vkbfm3XoKxn1z1qrfT6GRkX4X3YPjx6Bf9g9PHoEbAUJbuiHMV8motNEtImIZq4y/EbjjTAHIj8PCz8PjZ92Hrc458bW6ujqw558KPMh59xaQTo9NQc/Dz+Pbs7Dm/EeHj0C/7B7ePQIbtbD/shN+lzEG2EORH4eFn4eGtdtHjfFZ/fw8Og+vBnv4dEj6OrDzswfYuZjzHyCmbumRsvMf8rM08x8GP7WdSlsZt7OzI+15biPMPNnbsZcmDnHzD9h5hfa8/g37b/vYuan2vP4i7Z+wQ0HM4dtfcNv3Kx5MPMpZn6JmZ9n5kPtv92Me+SGybZ37WFn5pCI/gMR/RIR3UFEv87Md6z/ruuGLxHRh8zfboYUdouI/rlz7nYieisR/XZ7Dbo9lzoRvdc5dw8RHSSiDzHzW4noC0T0h+15zBPRp2/wPK7gM7QiT34FN2se73HOHQSq62bcIzdOtt0515V/RPQgEX0bXn+eiD7fxc/fSUSH4fUxIppstyeJ6Fi35gJz+BoRfeBmzoWICkT0LBG9hVaCN1JrXa8b+Pnb2jfwe4noG7QibXAz5nGKiDaZv3X1uhDRABGdpPZe2vWeRzfN+K1EdBZen2v/7WbhpkphM/NOIrqXiJ66GXNpm87P04pQ6HeJ6DUiWnAuEcTv1vX5IyL6lyRZTaM3aR6OiL7DzM8w88Ptv3X7utxQ2fZuPuxr1ZLtSSqAmfuI6K+I6HedM+loXYJzLnLOHaSVX9YHiOj2tYbdyDkw80eJaNo59wz+udvzaOPtzrn7aMXN/G1mfqgLn2lxTbLtV0M3H/ZzRIQ6TNuI6EKHsd3AhqSwrzeYOU0rD/qfOef++mbOhYjIObdAK9V83kpEQ8xJFcZuXJ+3E9HHmPkUEX2FVkz5P7oJ8yDn3IX2/9NE9De08gXY7etyTbLtV0M3H/aniWhfe6c1Q0SfJKKvd/HzLb5OKxLYRBuUwr5W8IqA3heJ6Khz7t/drLkw8xgzD7XbeSJ6P61sBD1GRJ/o1jycc593zm1zzu2klfvhe865f9TteTBzkZn7r7SJ6INEdJi6fF2ccxeJ6Cwz39b+0xXZ9uszjxu98WE2Gj5MRK/Sin/4e1383D8noikiatLKt+enacU3fJSIjrf/H+nCPN5BKybpi0T0fPvfh7s9FyI6QETPtedxmIj+z/bfdxPRT4joBBH9JRFlu3iN3k1E37gZ82h/3gvtf0eu3Js36R45SESH2tfmb4lo+HrNw0fQeXj0CHwEnYdHj8A/7B4ePQL/sHt49Aj8w+7h0SPwD7uHR4/AP+weHj0C/7B7ePQI/MPu4dEj+P8BZuQVdqKK3isAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating and testing dataset with WT & IWT\n",
    "random.seed(2020)\n",
    "root_dir = \"celeba64/\"\n",
    "image_files = os.listdir(root_dir)\n",
    "\n",
    "ds = CelebaDataset('celeba64/', image_files, WT=False)\n",
    "ds_loader = DataLoader(ds, batch_size=1, num_workers=10, shuffle=True)\n",
    "\n",
    "# Show original img\n",
    "t = ds[0]\n",
    "plt.imshow(t.numpy().transpose((1,2,0)))\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=2048):\n",
    "        return input.view(input.size(0), size, 1, 1)\n",
    "\n",
    "class UnFlatten1(nn.Module):        \n",
    "    def forward(self, input, size=3):\n",
    "        return input.view(input.size(0), size, 32, 32)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=2048, z_dim=100):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2), # N * 32 * 31 * 31\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2), # N * 64 * 14 * 14,\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2), # N * 128 * 6 * 6\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2), # N * 256 * 2 * 2\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride=1), # N * 512 * 2 * 2\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            Flatten()\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fct_decode_1 = nn.Sequential(\n",
    "            UnFlatten(),\n",
    "            nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2), # N * 128 * 5 * 5\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2), # N * 64 * 13 * 13\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2), # N * 64 * 30 * 30\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2), # N * 3 * 64 * 64\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.wt1 = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, image_channels, kernel_size=5, stride=1, padding=2), # N * 3 * 64 * 64\n",
    "            nn.BatchNorm2d(image_channels)\n",
    "        )\n",
    "        \n",
    "        self.wt2 = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, image_channels, kernel_size=5, stride=1, padding=2), # N * 3 * 64 * 64\n",
    "            nn.BatchNorm2d(image_channels)\n",
    "        )\n",
    "        \n",
    "#         self.wt3 = nn.Sequential(\n",
    "#             nn.Conv2d(image_channels, image_channels, kernel_size=5, stride=1, padding=2), # N * 3 * 64 * 64\n",
    "#             nn.BatchNorm2d(image_channels)\n",
    "#         )\n",
    "        \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            # return torch.normal(mu, std)\n",
    "            esp = torch.randn(*mu.size()).cuda()\n",
    "            z = mu + std * esp\n",
    "            return z\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = self.fct_decode_1(z)\n",
    "        z = self.wt1(z)\n",
    "        z = self.wt2(z)\n",
    "#         z = self.wt3(z)\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "       \n",
    "#         z_final = Variable(torch.stack([z_1,z_2,z_3,z_4], dim=1))\n",
    "#         z_final = z_final.view(-1,2,128//2,128//2).transpose(1,2).contiguous().view(-1,1,128,128)\n",
    "\n",
    "    def loss_function(self, wt_x, x, mu, logvar) -> Variable:\n",
    "        \n",
    "        wt_x = wt_x.view(-1,1,64,64)\n",
    "        x_recon = iwt(wt_x, levels=3)\n",
    "        x_recon = x_recon.view(-1,3,64,64)\n",
    "        x_recon = x_recon.contiguous()\n",
    "        \n",
    "        # Loss btw reconstructed img and original img\n",
    "        BCE = F.l1_loss(x_recon.view(-1, 3 * 64 * 64), x.view(-1, 3 * 64 * 64))\n",
    "\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) * 0.0001\n",
    "        KLD /= BATCH_SIZE * 3 * 64 * 64\n",
    "\n",
    "        return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch, model, optimizer, train_loader):\n",
    "    # toggle model to train mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        \n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        wt_batch, mu, logvar = model(data)\n",
    "        loss = model.loss_function(wt_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        train_loss += loss\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data),\n",
    "                                                                           len(train_loader.dataset),\n",
    "                                                                           100. * batch_idx / len(train_loader),\n",
    "                                                                           loss / len(data)))\n",
    "            \n",
    "            n = min(data.size(0), 8)\n",
    "           \n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CelebaDataset('celeba64/', image_files, WT=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA = True\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 0.029711\n",
      "Train Epoch: 1 [160/10000 (2%)]\tLoss: 0.018216\n",
      "Train Epoch: 1 [320/10000 (3%)]\tLoss: 0.013986\n",
      "Train Epoch: 1 [480/10000 (5%)]\tLoss: 0.012152\n",
      "Train Epoch: 1 [640/10000 (6%)]\tLoss: 0.011245\n",
      "Train Epoch: 1 [800/10000 (8%)]\tLoss: 0.011177\n",
      "Train Epoch: 1 [960/10000 (10%)]\tLoss: 0.010416\n",
      "Train Epoch: 1 [1120/10000 (11%)]\tLoss: 0.010637\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 0.010055\n",
      "Train Epoch: 1 [1440/10000 (14%)]\tLoss: 0.010354\n",
      "Train Epoch: 1 [1600/10000 (16%)]\tLoss: 0.010283\n",
      "Train Epoch: 1 [1760/10000 (18%)]\tLoss: 0.010158\n",
      "Train Epoch: 1 [1920/10000 (19%)]\tLoss: 0.009363\n",
      "Train Epoch: 1 [2080/10000 (21%)]\tLoss: 0.009649\n",
      "Train Epoch: 1 [2240/10000 (22%)]\tLoss: 0.009457\n",
      "Train Epoch: 1 [2400/10000 (24%)]\tLoss: 0.009215\n",
      "Train Epoch: 1 [2560/10000 (26%)]\tLoss: 0.009020\n",
      "Train Epoch: 1 [2720/10000 (27%)]\tLoss: 0.009271\n",
      "Train Epoch: 1 [2880/10000 (29%)]\tLoss: 0.009788\n",
      "Train Epoch: 1 [3040/10000 (30%)]\tLoss: 0.008500\n",
      "Train Epoch: 1 [3200/10000 (32%)]\tLoss: 0.008237\n",
      "Train Epoch: 1 [3360/10000 (34%)]\tLoss: 0.008303\n",
      "Train Epoch: 1 [3520/10000 (35%)]\tLoss: 0.008240\n",
      "Train Epoch: 1 [3680/10000 (37%)]\tLoss: 0.008792\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 0.007953\n",
      "Train Epoch: 1 [4000/10000 (40%)]\tLoss: 0.007640\n",
      "Train Epoch: 1 [4160/10000 (42%)]\tLoss: 0.007630\n",
      "Train Epoch: 1 [4320/10000 (43%)]\tLoss: 0.008808\n",
      "Train Epoch: 1 [4480/10000 (45%)]\tLoss: 0.007809\n",
      "Train Epoch: 1 [4640/10000 (46%)]\tLoss: 0.007613\n",
      "Train Epoch: 1 [4800/10000 (48%)]\tLoss: 0.007859\n",
      "Train Epoch: 1 [4960/10000 (50%)]\tLoss: 0.007650\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 0.007691\n",
      "Train Epoch: 1 [5280/10000 (53%)]\tLoss: 0.007825\n",
      "Train Epoch: 1 [5440/10000 (54%)]\tLoss: 0.007196\n",
      "Train Epoch: 1 [5600/10000 (56%)]\tLoss: 0.006979\n",
      "Train Epoch: 1 [5760/10000 (58%)]\tLoss: 0.007552\n",
      "Train Epoch: 1 [5920/10000 (59%)]\tLoss: 0.007413\n",
      "Train Epoch: 1 [6080/10000 (61%)]\tLoss: 0.007142\n",
      "Train Epoch: 1 [6240/10000 (62%)]\tLoss: 0.007177\n",
      "Train Epoch: 1 [6400/10000 (64%)]\tLoss: 0.006515\n",
      "Train Epoch: 1 [6560/10000 (65%)]\tLoss: 0.007302\n",
      "Train Epoch: 1 [6720/10000 (67%)]\tLoss: 0.007317\n",
      "Train Epoch: 1 [6880/10000 (69%)]\tLoss: 0.006711\n",
      "Train Epoch: 1 [7040/10000 (70%)]\tLoss: 0.006596\n",
      "Train Epoch: 1 [7200/10000 (72%)]\tLoss: 0.007868\n",
      "Train Epoch: 1 [7360/10000 (73%)]\tLoss: 0.006870\n",
      "Train Epoch: 1 [7520/10000 (75%)]\tLoss: 0.006745\n",
      "Train Epoch: 1 [7680/10000 (77%)]\tLoss: 0.006873\n",
      "Train Epoch: 1 [7840/10000 (78%)]\tLoss: 0.006656\n",
      "Train Epoch: 1 [8000/10000 (80%)]\tLoss: 0.007106\n",
      "Train Epoch: 1 [8160/10000 (81%)]\tLoss: 0.006995\n",
      "Train Epoch: 1 [8320/10000 (83%)]\tLoss: 0.006514\n",
      "Train Epoch: 1 [8480/10000 (85%)]\tLoss: 0.006505\n",
      "Train Epoch: 1 [8640/10000 (86%)]\tLoss: 0.006569\n",
      "Train Epoch: 1 [8800/10000 (88%)]\tLoss: 0.006398\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 0.006537\n",
      "Train Epoch: 1 [9120/10000 (91%)]\tLoss: 0.006619\n",
      "Train Epoch: 1 [9280/10000 (93%)]\tLoss: 0.006484\n",
      "Train Epoch: 1 [9440/10000 (94%)]\tLoss: 0.006259\n",
      "Train Epoch: 1 [9600/10000 (96%)]\tLoss: 0.006081\n",
      "Train Epoch: 1 [9760/10000 (97%)]\tLoss: 0.006762\n",
      "Train Epoch: 1 [9920/10000 (99%)]\tLoss: 0.006516\n",
      "====> Epoch: 1 Average loss: 0.0091\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 0.006958\n",
      "Train Epoch: 2 [160/10000 (2%)]\tLoss: 0.006296\n",
      "Train Epoch: 2 [320/10000 (3%)]\tLoss: 0.006811\n",
      "Train Epoch: 2 [480/10000 (5%)]\tLoss: 0.007005\n",
      "Train Epoch: 2 [640/10000 (6%)]\tLoss: 0.006411\n",
      "Train Epoch: 2 [800/10000 (8%)]\tLoss: 0.006076\n",
      "Train Epoch: 2 [960/10000 (10%)]\tLoss: 0.006698\n",
      "Train Epoch: 2 [1120/10000 (11%)]\tLoss: 0.006368\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 0.006540\n",
      "Train Epoch: 2 [1440/10000 (14%)]\tLoss: 0.006577\n",
      "Train Epoch: 2 [1600/10000 (16%)]\tLoss: 0.006961\n",
      "Train Epoch: 2 [1760/10000 (18%)]\tLoss: 0.006507\n",
      "Train Epoch: 2 [1920/10000 (19%)]\tLoss: 0.006081\n",
      "Train Epoch: 2 [2080/10000 (21%)]\tLoss: 0.006408\n",
      "Train Epoch: 2 [2240/10000 (22%)]\tLoss: 0.005847\n",
      "Train Epoch: 2 [2400/10000 (24%)]\tLoss: 0.005681\n",
      "Train Epoch: 2 [2560/10000 (26%)]\tLoss: 0.006375\n",
      "Train Epoch: 2 [2720/10000 (27%)]\tLoss: 0.006223\n",
      "Train Epoch: 2 [2880/10000 (29%)]\tLoss: 0.006216\n",
      "Train Epoch: 2 [3040/10000 (30%)]\tLoss: 0.006061\n",
      "Train Epoch: 2 [3200/10000 (32%)]\tLoss: 0.005988\n",
      "Train Epoch: 2 [3360/10000 (34%)]\tLoss: 0.006252\n",
      "Train Epoch: 2 [3520/10000 (35%)]\tLoss: 0.005869\n",
      "Train Epoch: 2 [3680/10000 (37%)]\tLoss: 0.005815\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 0.005942\n",
      "Train Epoch: 2 [4000/10000 (40%)]\tLoss: 0.006239\n",
      "Train Epoch: 2 [4160/10000 (42%)]\tLoss: 0.006055\n",
      "Train Epoch: 2 [4320/10000 (43%)]\tLoss: 0.006213\n",
      "Train Epoch: 2 [4480/10000 (45%)]\tLoss: 0.006162\n",
      "Train Epoch: 2 [4640/10000 (46%)]\tLoss: 0.006134\n",
      "Train Epoch: 2 [4800/10000 (48%)]\tLoss: 0.005768\n",
      "Train Epoch: 2 [4960/10000 (50%)]\tLoss: 0.005760\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 0.005371\n",
      "Train Epoch: 2 [5280/10000 (53%)]\tLoss: 0.005323\n",
      "Train Epoch: 2 [5440/10000 (54%)]\tLoss: 0.005920\n",
      "Train Epoch: 2 [5600/10000 (56%)]\tLoss: 0.005804\n",
      "Train Epoch: 2 [5760/10000 (58%)]\tLoss: 0.005655\n",
      "Train Epoch: 2 [5920/10000 (59%)]\tLoss: 0.005567\n",
      "Train Epoch: 2 [6080/10000 (61%)]\tLoss: 0.005435\n",
      "Train Epoch: 2 [6240/10000 (62%)]\tLoss: 0.005819\n",
      "Train Epoch: 2 [6400/10000 (64%)]\tLoss: 0.005626\n",
      "Train Epoch: 2 [6560/10000 (65%)]\tLoss: 0.005762\n",
      "Train Epoch: 2 [6720/10000 (67%)]\tLoss: 0.005919\n",
      "Train Epoch: 2 [6880/10000 (69%)]\tLoss: 0.006057\n",
      "Train Epoch: 2 [7040/10000 (70%)]\tLoss: 0.005855\n",
      "Train Epoch: 2 [7200/10000 (72%)]\tLoss: 0.005563\n",
      "Train Epoch: 2 [7360/10000 (73%)]\tLoss: 0.005828\n",
      "Train Epoch: 2 [7520/10000 (75%)]\tLoss: 0.005306\n",
      "Train Epoch: 2 [7680/10000 (77%)]\tLoss: 0.005901\n",
      "Train Epoch: 2 [7840/10000 (78%)]\tLoss: 0.005777\n",
      "Train Epoch: 2 [8000/10000 (80%)]\tLoss: 0.005995\n",
      "Train Epoch: 2 [8160/10000 (81%)]\tLoss: 0.005840\n",
      "Train Epoch: 2 [8320/10000 (83%)]\tLoss: 0.005702\n",
      "Train Epoch: 2 [8480/10000 (85%)]\tLoss: 0.005512\n",
      "Train Epoch: 2 [8640/10000 (86%)]\tLoss: 0.005331\n",
      "Train Epoch: 2 [8800/10000 (88%)]\tLoss: 0.005234\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 0.006085\n",
      "Train Epoch: 2 [9120/10000 (91%)]\tLoss: 0.005736\n",
      "Train Epoch: 2 [9280/10000 (93%)]\tLoss: 0.005424\n",
      "Train Epoch: 2 [9440/10000 (94%)]\tLoss: 0.005656\n",
      "Train Epoch: 2 [9600/10000 (96%)]\tLoss: 0.005399\n",
      "Train Epoch: 2 [9760/10000 (97%)]\tLoss: 0.004842\n",
      "Train Epoch: 2 [9920/10000 (99%)]\tLoss: 0.005744\n",
      "====> Epoch: 2 Average loss: 0.0060\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 0.005505\n",
      "Train Epoch: 3 [160/10000 (2%)]\tLoss: 0.005587\n",
      "Train Epoch: 3 [320/10000 (3%)]\tLoss: 0.005520\n",
      "Train Epoch: 3 [480/10000 (5%)]\tLoss: 0.004922\n",
      "Train Epoch: 3 [640/10000 (6%)]\tLoss: 0.005533\n",
      "Train Epoch: 3 [800/10000 (8%)]\tLoss: 0.005581\n",
      "Train Epoch: 3 [960/10000 (10%)]\tLoss: 0.005131\n",
      "Train Epoch: 3 [1120/10000 (11%)]\tLoss: 0.005165\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 0.005355\n",
      "Train Epoch: 3 [1440/10000 (14%)]\tLoss: 0.005268\n",
      "Train Epoch: 3 [1600/10000 (16%)]\tLoss: 0.005549\n",
      "Train Epoch: 3 [1760/10000 (18%)]\tLoss: 0.005265\n",
      "Train Epoch: 3 [1920/10000 (19%)]\tLoss: 0.004979\n",
      "Train Epoch: 3 [2080/10000 (21%)]\tLoss: 0.004830\n",
      "Train Epoch: 3 [2240/10000 (22%)]\tLoss: 0.005811\n",
      "Train Epoch: 3 [2400/10000 (24%)]\tLoss: 0.005499\n",
      "Train Epoch: 3 [2560/10000 (26%)]\tLoss: 0.005037\n",
      "Train Epoch: 3 [2720/10000 (27%)]\tLoss: 0.005416\n",
      "Train Epoch: 3 [2880/10000 (29%)]\tLoss: 0.005269\n",
      "Train Epoch: 3 [3040/10000 (30%)]\tLoss: 0.004829\n",
      "Train Epoch: 3 [3200/10000 (32%)]\tLoss: 0.005058\n",
      "Train Epoch: 3 [3360/10000 (34%)]\tLoss: 0.005084\n",
      "Train Epoch: 3 [3520/10000 (35%)]\tLoss: 0.005111\n",
      "Train Epoch: 3 [3680/10000 (37%)]\tLoss: 0.004916\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 0.005193\n",
      "Train Epoch: 3 [4000/10000 (40%)]\tLoss: 0.005071\n",
      "Train Epoch: 3 [4160/10000 (42%)]\tLoss: 0.005138\n",
      "Train Epoch: 3 [4320/10000 (43%)]\tLoss: 0.005646\n",
      "Train Epoch: 3 [4480/10000 (45%)]\tLoss: 0.005257\n",
      "Train Epoch: 3 [4640/10000 (46%)]\tLoss: 0.005092\n",
      "Train Epoch: 3 [4800/10000 (48%)]\tLoss: 0.005263\n",
      "Train Epoch: 3 [4960/10000 (50%)]\tLoss: 0.005350\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 0.005195\n",
      "Train Epoch: 3 [5280/10000 (53%)]\tLoss: 0.005356\n",
      "Train Epoch: 3 [5440/10000 (54%)]\tLoss: 0.004660\n",
      "Train Epoch: 3 [5600/10000 (56%)]\tLoss: 0.005171\n",
      "Train Epoch: 3 [5760/10000 (58%)]\tLoss: 0.005356\n",
      "Train Epoch: 3 [5920/10000 (59%)]\tLoss: 0.005230\n",
      "Train Epoch: 3 [6080/10000 (61%)]\tLoss: 0.004980\n",
      "Train Epoch: 3 [6240/10000 (62%)]\tLoss: 0.004911\n",
      "Train Epoch: 3 [6400/10000 (64%)]\tLoss: 0.005192\n",
      "Train Epoch: 3 [6560/10000 (65%)]\tLoss: 0.004811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [6720/10000 (67%)]\tLoss: 0.005126\n",
      "Train Epoch: 3 [6880/10000 (69%)]\tLoss: 0.005150\n",
      "Train Epoch: 3 [7040/10000 (70%)]\tLoss: 0.004503\n",
      "Train Epoch: 3 [7200/10000 (72%)]\tLoss: 0.004930\n",
      "Train Epoch: 3 [7360/10000 (73%)]\tLoss: 0.004953\n",
      "Train Epoch: 3 [7520/10000 (75%)]\tLoss: 0.004917\n",
      "Train Epoch: 3 [7680/10000 (77%)]\tLoss: 0.005174\n",
      "Train Epoch: 3 [7840/10000 (78%)]\tLoss: 0.004753\n",
      "Train Epoch: 3 [8000/10000 (80%)]\tLoss: 0.004953\n",
      "Train Epoch: 3 [8160/10000 (81%)]\tLoss: 0.004991\n",
      "Train Epoch: 3 [8320/10000 (83%)]\tLoss: 0.004916\n",
      "Train Epoch: 3 [8480/10000 (85%)]\tLoss: 0.005063\n",
      "Train Epoch: 3 [8640/10000 (86%)]\tLoss: 0.005056\n",
      "Train Epoch: 3 [8800/10000 (88%)]\tLoss: 0.004526\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 0.004953\n",
      "Train Epoch: 3 [9120/10000 (91%)]\tLoss: 0.004996\n",
      "Train Epoch: 3 [9280/10000 (93%)]\tLoss: 0.004736\n",
      "Train Epoch: 3 [9440/10000 (94%)]\tLoss: 0.005102\n",
      "Train Epoch: 3 [9600/10000 (96%)]\tLoss: 0.004526\n",
      "Train Epoch: 3 [9760/10000 (97%)]\tLoss: 0.004954\n",
      "Train Epoch: 3 [9920/10000 (99%)]\tLoss: 0.004872\n",
      "====> Epoch: 3 Average loss: 0.0052\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.005707\n",
      "Train Epoch: 4 [160/10000 (2%)]\tLoss: 0.004782\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-83f3ceffa9cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d653b241ec05>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, optimizer, train_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mwt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/swhan/anaconda3/envs/wmlce-1.6.2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d380fbc50a53>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d380fbc50a53>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/swhan/anaconda3/envs/wmlce-1.6.2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/swhan/anaconda3/envs/wmlce-1.6.2/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/swhan/anaconda3/envs/wmlce-1.6.2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/swhan/anaconda3/envs/wmlce-1.6.2/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/swhan/anaconda3/envs/wmlce-1.6.2/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1655\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m     )\n\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_losses = []\n",
    "# gc.collect()\n",
    "# EPOCHS = 100\n",
    "# model = VAE()\n",
    "# if CUDA: \n",
    "#     print('CUDA = {}'.format(CUDA))\n",
    "#     model.cuda()\n",
    "#     x_sample = torch.randn(32,3,64,64).cuda()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     train(epoch, model, optimizer, train_loader)\n",
    "\n",
    "#     # 64 sets of random ZDIMS-float vectors, i.e. 64 locations / MNIST\n",
    "#     # digits in latent space\n",
    "#     sample = Variable(torch.randn(32,100))\n",
    "#     if CUDA:\n",
    "#         sample = sample.cuda()\n",
    "#     x_sample1 = model.decode(sample)\n",
    "#     save_image(x_sample1[:8].cpu(), './image_samples/celeba-1/decoded_sample' + str(epoch) + '.png')  \n",
    "    \n",
    "#     x_sample1 = x_sample1.view(-1,1,64,64)\n",
    "#     x_sample1 = iwt(x_sample1, levels=3)\n",
    "#     x_sample1 = x_sample1.view(-1,3,64,64)\n",
    "# #     x_sample1 /= torch.max(x_sample1)\n",
    "    \n",
    "#     x_sample1 = x_sample1.contiguous()\n",
    "#     save_image(x_sample1[:8].cpu(), './image_samples/celeba-1/sample' + str(epoch) + '.png')  \n",
    "    \n",
    "#     torch.save(model.state_dict(), './models/wtvae64_models_rest0/wtvae_epoch{}.pth'.format(epoch))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wmlce-1.6.2",
   "language": "python",
   "name": "wmlce-1.6.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
